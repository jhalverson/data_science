{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jonathan Halverson\n",
    "# Saturday, December 30, 2017\n",
    "# Part I. Overcomplete to undercomplete autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the number of neurons in the single hidden layer is four times that of the number of inputs. This will prove to lead to a very small reconstruction loss but a terrible set of codings. The encoder is simply learning how to match the outputs to the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('halverson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('/tmp/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x105e6bf90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU4AAAFLCAYAAAC5nmXaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x181cf6dc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.train.images[0].reshape(28, 28), cmap='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Train the autoencoder (unsupervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 28 * 28\n",
    "n_units = 1 * n_inputs // 2\n",
    "n_outputs = n_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(dtype=tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "hidden = tf.layers.dense(X, n_units, activation=None, name='over_or_under_complete')\n",
    "outputs = tf.layers.dense(hidden, n_outputs, activation=None, name='outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reconstruction_loss = tf.reduce_mean(tf.square(X - outputs))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "training_op = optimizer.minimize(reconstruction_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "epochs = 10\n",
    "codings = hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.00481374\n",
      "2 0.00155759\n",
      "4 0.000862973\n",
      "6 0.000596635\n",
      "8 0.000498954\n",
      "10 0.000435496\n"
     ]
    }
   ],
   "source": [
    "ckpt_path = '/tmp/data/overcomplete_to_undercomplete_n_inputs_is_' + str(n_inputs) + '.ckpt'\n",
    "with tf.Session() as sess:\n",
    "     init.run()\n",
    "     for epoch in xrange(epochs + 1):\n",
    "          for iteration in xrange(mnist.train.num_examples // batch_size):\n",
    "               X_batch, _ = mnist.train.next_batch(batch_size)\n",
    "               sess.run(training_op, feed_dict={X:X_batch})\n",
    "          if not (epoch % 2): print epoch, reconstruction_loss.eval(feed_dict={X:mnist.validation.images})\n",
    "     save_path = saver.save(sess, ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = mnist.train.images\n",
    "y_train = mnist.train.labels\n",
    "X_test = mnist.test.images\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/data/overcomplete_to_undercomplete_n_inputs_is_784.ckpt\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWMAAAC9CAYAAABmgRwKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAATwH+cxZs3cFskBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107a0f990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "     saver.restore(sess, ckpt_path)\n",
    "     codings_train = codings.eval(feed_dict={X:X_train})\n",
    "     codings_test = codings.eval(feed_dict={X:X_test})\n",
    "     outputs_test = outputs.eval(feed_dict={X:X_test})\n",
    "     \n",
    "     plt.subplot(131)\n",
    "     plt.imshow(X_test[0].reshape(28, 28), cmap='binary'); plt.axis('off')\n",
    "     plt.subplot(132)\n",
    "     #plt.imshow(codings_test[0].reshape(56, 56), cmap='binary'); plt.axis('off')\n",
    "     #plt.subplot(133)\n",
    "     plt.imshow(outputs_test[0].reshape(28, 28), cmap='binary'); plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the accuracy using the codings of the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9173"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "SGDClassifier(loss='log', random_state=42, tol=1e-4).fit(codings_train, y_train).score(codings_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Freeze the hidden layer and add a FC layer with softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# modify the graph above, no reset here\n",
    "new_outputs = tf.layers.dense(hidden, units=10, activation=None, name='new_outputs')\n",
    "y = tf.placeholder(dtype=tf.int32, shape=(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'new_outputs/kernel:0' shape=(392, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'new_outputs/bias:0' shape=(10,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='new')\n",
    "train_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=new_outputs)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.005, name='Adam2')\n",
    "training_op = optimizer.minimize(loss, var_list=train_vars)\n",
    "correct = tf.nn.in_top_k(new_outputs, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/data/overcomplete_to_undercomplete_n_inputs_is_784.ckpt\n",
      "0 0.914 0.311368\n",
      "5 0.9223 0.275479\n",
      "10 0.9237 0.269579\n",
      "15 0.9232 0.269785\n",
      "20 0.9253 0.270357\n",
      "25 0.9257 0.273202\n",
      "30 0.9242 0.279122\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "     init.run()\n",
    "     saver.restore(sess, ckpt_path) # restore the variable values\n",
    "     #wts_before = [v for v in tf.trainable_variables() if v.name == \"hidden/kernel:0\"][0].eval()\n",
    "     for epoch in xrange(epochs + 1):\n",
    "          for iteration in xrange(mnist.train.num_examples // batch_size):\n",
    "               X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "               sess.run(training_op, feed_dict={X:X_batch, y:y_batch})\n",
    "          if not (epoch % 5): print epoch, accuracy.eval(feed_dict={X:X_test, y:y_test}), loss.eval(feed_dict={X:X_test, y:y_test})\n",
    "     #wts_after = [v for v in tf.trainable_variables() if v.name == \"hidden/kernel:0\"][0].eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| n_inputs | SGDClassifier Accuracy using Codings | Supervised Accuracy |\n",
    "|---|---|\n",
    "|2 x 784|91.8|92.1|\n",
    "|1 x 784|91.7|92.3|\n",
    "|784 / 2|91.8|92.4|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are independent of the number of neurons in the codings layer. The expectation was that the overcomplete autoencoder would lead to less accuracy when reused for the model trained with supervision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Codings accuracy versus number of neurons in hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we try a simpler case. We consider one hidden layer and vary its number of neurons. The accuracy is computed using SDGClassifier on the codings of the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 784\n",
    "n_units = 2*784\n",
    "n_outputs = n_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(dtype=tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "hidden = tf.layers.dense(X, n_units, activation=None, name='over_or_under_complete')\n",
    "outputs = tf.layers.dense(hidden, n_outputs, activation=None, name='outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reconstruction_loss = tf.reduce_mean(tf.square(X - outputs))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "training_op = optimizer.minimize(reconstruction_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "epochs = 20\n",
    "codings = hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.00116399\n",
      "2 6.28923e-05\n",
      "4 7.4095e-05\n",
      "6 5.52633e-05\n",
      "8 4.8892e-05\n",
      "10 3.26859e-05\n",
      "12 2.87289e-05\n",
      "14 0.000152808\n",
      "16 0.000145184\n",
      "18 7.73767e-05\n",
      "20 7.27525e-05\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "     init.run()\n",
    "     for epoch in xrange(epochs + 1):\n",
    "          for iteration in xrange(mnist.train.num_examples // batch_size):\n",
    "               X_batch, _ = mnist.train.next_batch(batch_size)\n",
    "               sess.run(training_op, feed_dict={X:X_batch})\n",
    "          if not (epoch % 2): print epoch, reconstruction_loss.eval(feed_dict={X:mnist.validation.images})\n",
    "     codings_train = codings.eval(feed_dict={X:X_train})\n",
    "     codings_test = codings.eval(feed_dict={X:X_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85919999999999996"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf = SGDClassifier(loss='log', random_state=42, tol=1e-4, penalty='l2', alpha=0.1)\n",
    "sgd_clf.fit(codings_train, y_train).score(codings_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91379999999999995"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf = SGDClassifier(loss='log', random_state=42, tol=1e-4, penalty='l2', alpha=0.001)\n",
    "sgd_clf.fit(codings_train, y_train).score(codings_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91679999999999995"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf = SGDClassifier(loss='log', random_state=42, tol=1e-4, penalty='l2', alpha=0.0001)\n",
    "sgd_clf.fit(codings_train, y_train).score(codings_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89929999999999999"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf = SGDClassifier(loss='log', random_state=42, tol=1e-4, penalty='l2', alpha=0.00001)\n",
    "sgd_clf.fit(codings_train, y_train).score(codings_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|neurons in coding layer|reconstruction loss|accuracy|\n",
    "|---|---|\n",
    "| 10|0.034|79|\n",
    "| 25|0.020|87|\n",
    "| 50|0.012|90|\n",
    "|100|0.0058|91|\n",
    "|250|0.0016|91|\n",
    "|500|0.0001|91|\n",
    "|784|5e-5|91|\n",
    "|1568|5e-5|91|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that as the number of neurons increases the reconstruction loss and accuracy increase until the two saturate. We note that using about 75 neurons gives the same accuracy as a larger number. This is the value we would choose if we were using the autoencoder for dimensionality reduction."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
