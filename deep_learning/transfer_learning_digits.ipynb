{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jonathan Halverson\n",
    "# Friday, November 17, 2017\n",
    "# Transfer learning (problem 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('halverson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 28 * 28\n",
    "n_hidden = 100\n",
    "n_outputs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(dtype=tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(dtype=tf.int64, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "he_init = [tf.contrib.layers.variance_scaling_initializer(seed=s) for s in [1234, 3456, 5678, 7890, 9012]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('hidden_layers') as scope:\n",
    "     hidden1 = tf.layers.dense(X      , n_hidden, activation=tf.nn.elu, kernel_initializer=he_init[0], name=\"hidden1\")\n",
    "     hidden2 = tf.layers.dense(hidden1, n_hidden, activation=tf.nn.elu, kernel_initializer=he_init[1], name=\"hidden2\")\n",
    "     hidden3 = tf.layers.dense(hidden2, n_hidden, activation=tf.nn.elu, kernel_initializer=he_init[2], name=\"hidden3\")\n",
    "     hidden4 = tf.layers.dense(hidden3, n_hidden, activation=tf.nn.elu, kernel_initializer=he_init[3], name=\"hidden4\")\n",
    "     hidden5 = tf.layers.dense(hidden4, n_hidden, activation=tf.nn.elu, kernel_initializer=he_init[4], name=\"hidden5\")\n",
    "     logits  = tf.layers.dense(hidden5, n_outputs, activation=None, name=\"logits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#correct = tf.nn.in_top_k(logits, y, 1)\n",
    "#accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "accuracy_, accuracy_op = tf.metrics.accuracy(y, tf.arg_max(logits, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy_train_summary = tf.summary.scalar('train_accuracy', accuracy_op)\n",
    "accuracy_test_summary = tf.summary.scalar('test_accuracy', accuracy_op)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_digits(A, b, i):\n",
    "     msk = (b <= i)\n",
    "     return A[msk].copy(), b[msk].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_train_04, labels_train_04 = filter_digits(mnist.train.images, mnist.train.labels, 4)\n",
    "images_test_04, labels_test_04 = filter_digits(mnist.test.images, mnist.test.labels, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_batch(A, b, batch_size):\n",
    "     # could use randint and bootstrapping\n",
    "     indices = np.random.choice(range(A.shape[0]), size=batch_size, replace=False)\n",
    "     return A[indices], b[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'Train accuracy=', 0.97959918, 'Test accuracy=', 0.9792096)\n",
      "(10, 'Train accuracy=', 0.98887986, 'Test accuracy=', 0.98901737)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "     init.run()\n",
    "     sess.run(tf.local_variables_initializer()) # needed for metrics\n",
    "     for epoch in range(n_epochs + 1):\n",
    "          for iteration in range(images_train_04.shape[0] // batch_size):\n",
    "               X_batch, y_batch = fetch_batch(images_train_04, labels_train_04, batch_size)\n",
    "               sess.run(training_op, feed_dict={X:X_batch, y:y_batch})\n",
    "          # tensorboard\n",
    "          accuracy_train_tb = accuracy_train_summary.eval(feed_dict={X:X_batch, y:y_batch})\n",
    "          accuracy_test_tb = accuracy_test_summary.eval(feed_dict={X:images_test_04, y:labels_test_04})\n",
    "          file_writer.add_summary(accuracy_train_tb, epoch)\n",
    "          file_writer.add_summary(accuracy_test_tb, epoch)\n",
    "          save_path = saver.save(sess, '/tmp/adam_five_layers.ckpt')\n",
    "          accuracy_train = accuracy_op.eval(feed_dict={X:X_batch, y:y_batch})\n",
    "          accuracy_test = accuracy_op.eval(feed_dict={X:images_test_04, y:labels_test_04})\n",
    "          if (epoch % 10 == 0): print(epoch, \"Train accuracy=\", accuracy_train, \"Test accuracy=\", accuracy_test)\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the weights of the first hidden layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wts = [v for v in tf.trainable_variables() if v.name == \"hidden1/kernel:0\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = tf.get_default_graph()\n",
    "assign_kernel = graph.get_operation_by_name('hidden1/kernel/Assign')\n",
    "init_kernel = assign_kernel.inputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02956573 -0.0147317   0.03754659 ...,  0.0100181  -0.04642533\n",
      "  -0.00392781]\n",
      " [ 0.00681664  0.01608448 -0.06526339 ...,  0.05845329  0.06846888\n",
      "  -0.01446561]\n",
      " [ 0.01235745 -0.00840173  0.04258089 ..., -0.00761735  0.01835208\n",
      "   0.10508064]\n",
      " ..., \n",
      " [-0.10877235 -0.00780591 -0.06775687 ..., -0.05455706  0.01110328\n",
      "  -0.07342914]\n",
      " [ 0.00898654  0.02877282 -0.08861893 ...,  0.00292607  0.0988029\n",
      "  -0.10259175]\n",
      " [ 0.06239619  0.00710347 -0.02129543 ..., -0.01523922 -0.02762903\n",
      "  -0.04033452]]\n",
      "[[ 0.00197871 -0.09727467  0.03001994 ..., -0.03357524  0.02215341\n",
      "   0.01172276]\n",
      " [ 0.0351553   0.03946508  0.09650076 ...,  0.05853136  0.05950334\n",
      "   0.00707132]\n",
      " [-0.08648536 -0.02498405 -0.02373177 ..., -0.00258497  0.06656438\n",
      "  -0.03916783]\n",
      " ..., \n",
      " [-0.00804007  0.05561004 -0.03737677 ..., -0.05511406 -0.08602148\n",
      "  -0.10004824]\n",
      " [-0.00557009 -0.01244225 -0.02345512 ..., -0.01570851  0.02791833\n",
      "   0.09433575]\n",
      " [-0.01495138  0.01993305 -0.01939865 ..., -0.00214882 -0.0788036\n",
      "  -0.04288276]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as tf:\n",
    "     init.run()\n",
    "     print wts.eval()\n",
    "     print init_kernel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"hidden1/kernel/Initializer/truncated_normal:0\", shape=(784, 100), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print init_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Use the hidden layers from the first model in a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Session' object has no attribute 'Session'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-2686da4dbe84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m      \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_meta_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/tmp/adam_five_layers.meta\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Session' object has no attribute 'Session'"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "     saver = tf.train.import_meta_graph(sess, \"/tmp/adam_five_layers.meta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='hidden[123]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reuse_vars_dict = dict([(var.op.name, var) for var in reuse_vars])\n",
    "restore_saver = tf.train.Saver(reuse_vars_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializers()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "     init.run()\n",
    "     restore_saver.restore(sess, '/tmp/my_model_chckpt.ckpt')\n",
    "     # train the model\n",
    "     save_path = saver.save(sess, '/tmp/my_new_final_model.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
