{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jonathan Halverson\n",
    "# Friday, November 17, 2017\n",
    "# Transfer learning (problem 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('halverson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 28 * 28\n",
    "n_hidden = 100\n",
    "n_outputs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(dtype=tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(dtype=tf.int64, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "he_init = [tf.contrib.layers.variance_scaling_initializer(seed=s) for s in [1234, 3456, 5678, 7890, 9012]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('hidden_layers') as scope:\n",
    "     hidden1 = tf.layers.dense(X      , n_hidden, activation=tf.nn.elu, kernel_initializer=he_init[0], name=\"hidden1\")\n",
    "     hidden2 = tf.layers.dense(hidden1, n_hidden, activation=tf.nn.elu, kernel_initializer=he_init[1], name=\"hidden2\")\n",
    "     hidden3 = tf.layers.dense(hidden2, n_hidden, activation=tf.nn.elu, kernel_initializer=he_init[2], name=\"hidden3\")\n",
    "     hidden4 = tf.layers.dense(hidden3, n_hidden, activation=tf.nn.elu, kernel_initializer=he_init[3], name=\"hidden4\")\n",
    "     hidden5 = tf.layers.dense(hidden4, n_hidden, activation=tf.nn.elu, kernel_initializer=he_init[4], name=\"hidden5\")\n",
    "     logits  = tf.layers.dense(hidden5, n_outputs, activation=None, name=\"logits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "#accuracy_, accuracy_op = tf.metrics.accuracy(y, tf.arg_max(logits, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#accuracy_train_summary = tf.summary.scalar('train_accuracy', accuracy_op)\n",
    "#accuracy_test_summary = tf.summary.scalar('test_accuracy', accuracy_op)\n",
    "accuracy_train_summary = tf.summary.scalar('train_accuracy', accuracy)\n",
    "accuracy_test_summary = tf.summary.scalar('test_accuracy', accuracy)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_digits(A, b, i):\n",
    "     msk = (b <= i)\n",
    "     return A[msk].copy(), b[msk].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_train_04, labels_train_04 = filter_digits(mnist.train.images, mnist.train.labels, 4)\n",
    "images_valid_04, labels_valid_04 = filter_digits(mnist.validation.images, mnist.validation.labels, 4)\n",
    "images_test_04, labels_test_04 = filter_digits(mnist.test.images, mnist.test.labels, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.min(), mnist.train.images.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_batch(A, b, batch_size):\n",
    "     # could use randint and bootstrapping\n",
    "     indices = np.random.choice(range(A.shape[0]), size=batch_size, replace=False)\n",
    "     return A[indices], b[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'Train accuracy=', 0.98000002, 'Test accuracy=', 0.98279905)\n",
      "(10, 'Train accuracy=', 1.0, 'Test accuracy=', 0.99061769)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "     init.run()\n",
    "     #sess.run(tf.local_variables_initializer()) # needed for metrics\n",
    "     for epoch in range(n_epochs + 1):\n",
    "          for iteration in range(images_train_04.shape[0] // batch_size):\n",
    "               X_batch, y_batch = fetch_batch(images_train_04, labels_train_04, batch_size)\n",
    "               sess.run(training_op, feed_dict={X:X_batch, y:y_batch})\n",
    "          # tensorboard\n",
    "          accuracy_train_tb = accuracy_train_summary.eval(feed_dict={X:X_batch, y:y_batch})\n",
    "          accuracy_test_tb = accuracy_test_summary.eval(feed_dict={X:images_test_04, y:labels_test_04})\n",
    "          file_writer.add_summary(accuracy_train_tb, epoch)\n",
    "          file_writer.add_summary(accuracy_test_tb, epoch)\n",
    "          save_path = saver.save(sess, '/tmp/adam_five_layers.ckpt')\n",
    "          #accuracy_train = accuracy_op.eval(feed_dict={X:X_batch, y:y_batch})\n",
    "          #accuracy_test = accuracy_op.eval(feed_dict={X:images_valid_04, y:labels_valid_04})\n",
    "          accuracy_train = accuracy.eval(feed_dict={X:X_batch, y:y_batch})\n",
    "          accuracy_test = accuracy.eval(feed_dict={X:images_valid_04, y:labels_valid_04})\n",
    "          if (epoch % 10 == 0): print(epoch, \"Train accuracy=\", accuracy_train, \"Test accuracy=\", accuracy_test)\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[v.name for v in tf.global_variables()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[v.name for v in tf.trainable_variables()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the weights of the first hidden layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wts = [v for v in tf.trainable_variables() if v.name == \"hidden1/kernel:0\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = tf.get_default_graph()\n",
    "assign_kernel = graph.get_operation_by_name('hidden1/kernel/Assign')\n",
    "init_kernel = assign_kernel.inputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "     init.run()\n",
    "     print wts.eval()\n",
    "     print init_kernel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print init_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Use the hidden layers from the first model in a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "     saver.restore(sess, \"/tmp/adam_five_layers.ckpt\")\n",
    "     #saver = tf.train.import_meta_graph(sess, \"/tmp/adam_five_layers.meta\")\n",
    "     X_new = images_train_04[0:3]\n",
    "     Z = logits.eval(feed_dict={X:X_new})\n",
    "     y_pred = np.argmax(Z, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred, labels_train_04[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows that the model was restored and used to make correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for op in tf.get_default_graph().get_operations():\n",
    "     if ('kernel' in op.name and 'Adam' not in op.name): print (op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='hidden[123]')\n",
    "reuse_vars_dict = dict([(var.op.name, var) for var in reuse_vars])\n",
    "restore_saver = tf.train.Saver(reuse_vars_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "     init.run()\n",
    "     restore_saver.restore(sess, '/tmp/my_model_chckpt.ckpt')\n",
    "     # train the model\n",
    "     save_path = saver.save(sess, '/tmp/my_new_final_model.ckpt')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
