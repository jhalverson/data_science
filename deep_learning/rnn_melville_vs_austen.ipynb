{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jonathan Halverson\n",
    "# Wednesday, January 17, 2018\n",
    "# Melville versus Austen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we train an RNN to classify sentences as written by either Herman Melville or Jane Austen. We have 12,500 sentences between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('halverson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "melville_raw = list(nltk.corpus.gutenberg.words('melville-moby_dick.txt'))\n",
    "austen_raw = list(nltk.corpus.gutenberg.words('austen-sense.txt'))\n",
    "austen_raw2 = list(nltk.corpus.gutenberg.words('austen-persuasion.txt'))\n",
    "austen_raw3 = list(nltk.corpus.gutenberg.words('austen-emma.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "melville = melville_raw[melville_raw.index('Loomings'):]\n",
    "austen = austen_raw[austen_raw.index('The'):]\n",
    "austen2 = austen_raw2[austen_raw2.index('Sir'):]\n",
    "austen3 = austen_raw3[austen_raw3.index('I'):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('melville_pierre.txt') as f:\n",
    "     melville2 = f.read().decode('utf-8').encode('ascii', 'ignore').replace('\\n', ' ').split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_sentences(x):\n",
    "     j = ' '.join(x).replace('Mr .', 'Mr').replace('Mrs .', 'Mrs')\n",
    "     j = j.replace('Ms .', 'Ms').replace('Dr .', 'Dr').replace('\\n', ' ')\n",
    "     j = j.replace('?', '.').replace('!', '.').replace('CHAPTER', ' ')\n",
    "     sentences = j.split('.')\n",
    "     s = [re.sub(\"[^a-zA-Z]\", \" \", sentence) for sentence in sentences]\n",
    "     s = [sentence.lower().split() for sentence in s]\n",
    "     return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_single_letters_except_ia(sentences):\n",
    "     new_sentences = []\n",
    "     for sentence in sentences:\n",
    "          cleaned_sentence = []\n",
    "          for word in sentence:\n",
    "               if len(word) > 1:\n",
    "                    cleaned_sentence.append(word)\n",
    "               else:\n",
    "                    if word in ['a', 'i']:\n",
    "                         cleaned_sentence.append(word)\n",
    "          new_sentences.append(cleaned_sentence)\n",
    "     return new_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_short_and_long_sentences(sentences, low, high):\n",
    "     new_sentences = []\n",
    "     for sentence in sentences:\n",
    "          if (len(sentence) >= low and len(sentence) <= high):\n",
    "               new_sentences.append(sentence)\n",
    "     return new_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_word_with_index_and_zero_pad(sentences, dictionary, high):\n",
    "     number_sentences = []\n",
    "     for sentence in sentences:\n",
    "          # how to handle words not in vocabulary\n",
    "          number_sentence = [dictionary[word] for word in sentence]\n",
    "          for _ in range(high - len(number_sentence)):\n",
    "               number_sentence.append(0)\n",
    "          number_sentences.append(number_sentence)\n",
    "     return number_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1 = remove_single_letters_except_ia(make_sentences(melville)) + \\\n",
    "     remove_single_letters_except_ia(make_sentences(melville2))\n",
    "s2 = remove_single_letters_except_ia(make_sentences(austen)) + \\\n",
    "     remove_single_letters_except_ia(make_sentences(austen2)) + \\\n",
    "     remove_single_letters_except_ia(make_sentences(austen3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "upper_bound = 15\n",
    "s1 = remove_short_and_long_sentences(s1, 5, upper_bound)\n",
    "s2 = remove_short_and_long_sentences(s2, 5, upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5247 7298\n"
     ]
    }
   ],
   "source": [
    "print len(s1), len(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq_length = np.array([len(sentence) for sentence in s1] + [len(sentence) for sentence in s2])\n",
    "target = np.append(np.ones(len(s1)), np.zeros(len(s2))).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_words = [word for sentence in s1 for word in sentence] + \\\n",
    "            [word for sentence in s2 for word in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119046"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9887"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = set(all_words)\n",
    "vocabulary_size = len(unique_words)\n",
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = dict([(word, index) for index, word in enumerate(unique_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_sentences = replace_word_with_index_and_zero_pad(s1, dictionary, high=upper_bound) + \\\n",
    "                replace_word_with_index_and_zero_pad(s2, dictionary, high=upper_bound)\n",
    "all_sentences = np.array(all_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = np.arange(target.size)\n",
    "np.random.shuffle(idx)\n",
    "all_sentences = all_sentences[idx]\n",
    "target = target[idx]\n",
    "seq_length = seq_length[idx]\n",
    "\n",
    "\n",
    "seq_length = np.array(seq_length.size * [3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "idx_cut = int((1.0 - test_size) * target.size)\n",
    "X_training = all_sentences[:idx_cut]\n",
    "X_test = all_sentences[idx_cut:]\n",
    "y_training = target[:idx_cut]\n",
    "y_test = target[idx_cut:]\n",
    "L_training = seq_length[:idx_cut]\n",
    "L_test = seq_length[idx_cut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_batch(A, b, c, batch_size):\n",
    "     idx = np.random.choice(np.arange(y_training.size), size=batch_size, replace=False)\n",
    "     return A[idx], b[idx], c[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_size = 32\n",
    "n_inputs = embedding_size\n",
    "n_steps = 15\n",
    "n_neurons = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.int32, shape=(None, n_steps))\n",
    "y = tf.placeholder(tf.int32, shape=(None))\n",
    "L = tf.placeholder(dtype=tf.int32, shape=(None))\n",
    "training = tf.placeholder_with_default(False, shape=(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0), trainable=True)\n",
    "embed = tf.nn.embedding_lookup(params=embeddings, ids=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cell = tf.contrib.rnn.GRUCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(cell, embed, dtype=tf.float32, sequence_length=L)\n",
    "fc_drop = tf.layers.dropout(states, rate=0.9, training=training)\n",
    "logits_2d = tf.layers.dense(fc_drop, units=1, activation=None)\n",
    "logits = tf.squeeze(logits_2d)\n",
    "y_proba = tf.nn.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.cast(y, tf.float32), logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = tf.cast(tf.greater(logits, 0.0), tf.int32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(y, y_pred), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 75\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.535514 0.706667 0.534351 0.722599\n",
      "5 0.342327 0.853333 0.574346 0.763252\n",
      "10 0.218669 0.893333 0.70296 0.758868\n",
      "15 0.248945 0.893333 0.727395 0.759267\n",
      "20 0.287286 0.906667 0.81924 0.757672\n",
      "25 0.18529 0.906667 0.84474 0.750897\n",
      "30 0.21924 0.893333 0.874485 0.75568\n",
      "35 0.166572 0.946667 0.922816 0.761259\n",
      "40 0.207608 0.906667 0.974304 0.754882\n",
      "45 0.194142 0.893333 0.974424 0.75847\n",
      "50 0.256801 0.906667 0.95818 0.75847\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "     init.run()\n",
    "     for epoch in xrange(epochs + 1):\n",
    "          for iteration in xrange(y_training.size // batch_size):\n",
    "               X_batch, y_batch, L_batch = fetch_batch(X_training, y_training, L_training, batch_size)\n",
    "               sess.run(training_op, feed_dict={X:X_batch, y:y_batch, L:L_batch, training:True})\n",
    "          if epoch % 5 == 0:\n",
    "               loss_batch, acc_batch = sess.run([loss, accuracy], feed_dict={X:X_batch, y:y_batch, L:L_batch, training:False})\n",
    "               loss_test, acc_test = sess.run([loss, accuracy], feed_dict={X:X_test, y:y_test, L:L_test, training:False})\n",
    "               print epoch, loss_batch, acc_batch, loss_test, acc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|n_neurons|embedding_size|embeddings_trainable|dropout_rate|dropout_during_testing|sequence|peak accuracy|\n",
    "|------|------|------|------|------|------|\n",
    "| 64 | 64| yes| 0.9|no|var|87.0%|\n",
    "| 64 | 64| yes| 0.9|yes|var|85.6%|\n",
    "| 64 | 64| no| 0.9|no|var|79.9%|\n",
    "| 32 | 32| yes| 0.9|no|var|87.2%|\n",
    "| 16 | 16| yes| 0.9|no|var|86.2%|\n",
    "| 8 | 8| yes| 0.9|no|var|87.4%|\n",
    "| 2 | 2| yes| 0.9|no|var|86.7%|\n",
    "| 32 | 32| yes| 0.9|no|all 25|86.1%|\n",
    "| 32 | 32| yes| 0.9|no|all 5|79.7%|\n",
    "| 32 | 32| yes| 0.9|no|all 3|76.3%|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conventional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60900757273814266"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestClassifier(n_estimators=25).fit(X_training, y_training).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside on sequence length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://r2rt.com/recurrent-neural-networks-in-tensorflow-iii-variable-length-sequences.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model doesn't make much sense given the zero padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "seq_length = tf.placeholder(tf.int32, (None))\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "output_seqs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32, sequence_length=seq_length)\n",
    "\n",
    "# this a general way of obtaining the last output (and may be different to states (e.g., stacked cells))\n",
    "idx = tf.range(4) * tf.shape(output_seqs)[1] + (seq_length - 1)\n",
    "last_rnn_output = tf.gather(tf.reshape(output_seqs, [-1, n_neurons]), idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_batch = np.array([\n",
    "        # t = 0      t = 1 \n",
    "        [[0, 1, 2], [9, 8, 7]], # instance 1\n",
    "        [[3, 4, 5], [1e6, 1e6, 1e6]], # instance 2\n",
    "        [[6, 7, 8], [6, 5, 4]], # instance 3\n",
    "        [[9, 0, 1], [3, 2, 1]], # instance 4\n",
    "    ])\n",
    "seq_length_batch = [2, 1, 2, 2]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "     init.run()\n",
    "     outputs_val = output_seqs.eval(feed_dict={X: X_batch, seq_length:seq_length_batch})\n",
    "     states_val = states.eval(feed_dict={X: X_batch, seq_length:seq_length_batch})\n",
    "     last_rnn_output = states.eval(feed_dict={X: X_batch, seq_length:seq_length_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.51830071 -0.55948418 -0.03514713  0.94566482  0.74650013]\n",
      "  [ 0.99999982  0.99294418  0.93391019  1.          0.99999839]]\n",
      "\n",
      " [[ 0.99788857 -0.05489642  0.53856391  0.99999613  0.99871683]\n",
      "  [ 0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.99999297  0.47937977  0.84529084  1.          0.99999428]\n",
      "  [ 0.99976665  0.99478036  0.70588583  0.99999905  0.99995583]]\n",
      "\n",
      " [[ 0.99777275  0.71935076  0.99963731  0.99936914  0.99851298]\n",
      "  [ 0.91072702  0.98585087  0.25284082  0.98582256  0.99335402]]]\n"
     ]
    }
   ],
   "source": [
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.99999982  0.99294418  0.93391019  1.          0.99999839]\n",
      " [ 0.99788857 -0.05489642  0.53856391  0.99999613  0.99871683]\n",
      " [ 0.99976665  0.99478036  0.70588583  0.99999905  0.99995583]\n",
      " [ 0.91072702  0.98585087  0.25284082  0.98582256  0.99335402]]\n"
     ]
    }
   ],
   "source": [
    "print(states_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.99999982  0.99294418  0.93391019  1.          0.99999839]\n",
      " [ 0.99788857 -0.05489642  0.53856391  0.99999613  0.99871683]\n",
      " [ 0.99976665  0.99478036  0.70588583  0.99999905  0.99995583]\n",
      " [ 0.91072702  0.98585087  0.25284082  0.98582256  0.99335402]]\n"
     ]
    }
   ],
   "source": [
    "print(last_rnn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(states_val, last_rnn_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This test shows that no matter the input, the final state is set by the sequence length as expected. This is important because the word embeddings for key 0 will be entered but the sequence length will not allow the result to be used. Hence one does not need to zero pad but could put in any inputs beyond the sequence length such as 1e6."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
