{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jonathan Halverson\n",
    "# Wednesday, January 17, 2018\n",
    "# Melville versus Austen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we train an RNN to classify sentences as written by either Herman Melville or Jane Austen. We have 12,500 sentences between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('halverson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "melville_raw = list(nltk.corpus.gutenberg.words('melville-moby_dick.txt'))\n",
    "austen_raw = list(nltk.corpus.gutenberg.words('austen-sense.txt'))\n",
    "austen_raw2 = list(nltk.corpus.gutenberg.words('austen-persuasion.txt'))\n",
    "austen_raw3 = list(nltk.corpus.gutenberg.words('austen-emma.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "melville = melville_raw[melville_raw.index('Loomings'):]\n",
    "austen = austen_raw[austen_raw.index('The'):]\n",
    "austen2 = austen_raw2[austen_raw2.index('Sir'):]\n",
    "austen3 = austen_raw3[austen_raw3.index('I'):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('melville_pierre.txt') as f:\n",
    "     melville2 = f.read().decode('utf-8').encode('ascii', 'ignore').replace('\\n', ' ').split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_sentences(x):\n",
    "     j = ' '.join(x).replace('Mr .', 'Mr').replace('Mrs .', 'Mrs')\n",
    "     j = j.replace('Ms .', 'Ms').replace('Dr .', 'Dr').replace('\\n', ' ')\n",
    "     j = j.replace('?', '.').replace('!', '.').replace('CHAPTER', ' ')\n",
    "     sentences = j.split('.')\n",
    "     s = [re.sub(\"[^a-zA-Z]\", \" \", sentence) for sentence in sentences]\n",
    "     s = [sentence.lower().split() for sentence in s]\n",
    "     return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_single_letters_except_ia(sentences):\n",
    "     new_sentences = []\n",
    "     for sentence in sentences:\n",
    "          cleaned_sentence = []\n",
    "          for word in sentence:\n",
    "               if len(word) > 1:\n",
    "                    cleaned_sentence.append(word)\n",
    "               else:\n",
    "                    if word in ['a', 'i']:\n",
    "                         cleaned_sentence.append(word)\n",
    "          new_sentences.append(cleaned_sentence)\n",
    "     return new_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_short_and_long_sentences(sentences, low, high):\n",
    "     new_sentences = []\n",
    "     for sentence in sentences:\n",
    "          if (len(sentence) >= low and len(sentence) <= high):\n",
    "               new_sentences.append(sentence)\n",
    "     return new_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_word_with_index_and_zero_pad(sentences, dictionary, high):\n",
    "     number_sentences = []\n",
    "     for sentence in sentences:\n",
    "          # how to handle words not in vocabulary\n",
    "          number_sentence = [dictionary[word] for word in sentence]\n",
    "          for _ in range(high - len(number_sentence)):\n",
    "               number_sentence.append(0)\n",
    "          number_sentences.append(number_sentence)\n",
    "     return number_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1 = remove_single_letters_except_ia(make_sentences(melville)) + \\\n",
    "     remove_single_letters_except_ia(make_sentences(melville2))\n",
    "s2 = remove_single_letters_except_ia(make_sentences(austen)) + \\\n",
    "     remove_single_letters_except_ia(make_sentences(austen2)) + \\\n",
    "     remove_single_letters_except_ia(make_sentences(austen3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "upper_bound = 15\n",
    "s1 = remove_short_and_long_sentences(s1, 5, upper_bound)\n",
    "s2 = remove_short_and_long_sentences(s2, 5, upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5247 7298\n"
     ]
    }
   ],
   "source": [
    "print len(s1), len(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq_length = np.array([len(sentence) for sentence in s1] + [len(sentence) for sentence in s2])\n",
    "target = np.append(np.ones(len(s1)), np.zeros(len(s2))).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_words = [word for sentence in s1 for word in sentence] + \\\n",
    "            [word for sentence in s2 for word in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119046"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9887"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = set(all_words)\n",
    "vocabulary_size = len(unique_words)\n",
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = dict([(word, index) for index, word in enumerate(unique_words)])\n",
    "#dictionary['UNK'] = vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_sentences = replace_word_with_index_and_zero_pad(s1, dictionary, high=upper_bound) + \\\n",
    "                replace_word_with_index_and_zero_pad(s2, dictionary, high=upper_bound)\n",
    "all_sentences = np.array(all_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = np.arange(target.size)\n",
    "np.random.shuffle(idx)\n",
    "all_sentences = all_sentences[idx]\n",
    "target = target[idx]\n",
    "seq_length = seq_length[idx]\n",
    "\n",
    "\n",
    "#seq_length = np.array(seq_length.size * [25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "idx_cut = int((1.0 - test_size) * target.size)\n",
    "X_training = all_sentences[idx_cut:]\n",
    "X_test = all_sentences[:idx_cut]\n",
    "y_training = target[idx_cut:]\n",
    "y_test = target[:idx_cut]\n",
    "L_training = seq_length[idx_cut:]\n",
    "L_test = seq_length[:idx_cut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_batch(A, b, c, batch_size):\n",
    "     idx = np.random.choice(np.arange(y_training.size), size=batch_size, replace=False)\n",
    "     return A[idx], b[idx], c[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_size = 64/2\n",
    "n_inputs = embedding_size\n",
    "n_steps = 15\n",
    "n_neurons = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.int32, shape=(None, n_steps))\n",
    "y = tf.placeholder(tf.int32, shape=(None))\n",
    "L = tf.placeholder(dtype=tf.int32, shape=(None))\n",
    "training = tf.placeholder_with_default(False, shape=(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0), trainable=True)\n",
    "embed = tf.nn.embedding_lookup(params=embeddings, ids=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cell = tf.contrib.rnn.GRUCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(cell, embed, dtype=tf.float32, sequence_length=L)\n",
    "fc_drop = tf.layers.dropout(states, rate=0.9, training=training)\n",
    "logits_2d = tf.layers.dense(fc_drop, units=1, activation=None)\n",
    "logits = tf.squeeze(logits_2d)\n",
    "y_proba = tf.nn.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.cast(y, tf.float32), logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = tf.cast(tf.greater(logits, 0.0), tf.int32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(y, y_pred), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 75\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.507736 0.72 0.548803 0.725189\n",
      "5 0.13829 0.973333 0.781159 0.802112\n",
      "10 0.00724304 1.0 1.31518 0.796333\n",
      "15 0.0175522 0.986667 1.37547 0.805998\n",
      "20 0.00079619 1.0 1.43582 0.799322\n",
      "25 7.21237e-05 1.0 1.49908 0.804404\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "     init.run()\n",
    "     for epoch in xrange(epochs + 1):\n",
    "          for iteration in xrange(y_training.size // batch_size):\n",
    "               X_batch, y_batch, L_batch = fetch_batch(X_training, y_training, L_training, batch_size)\n",
    "               sess.run(training_op, feed_dict={X:X_batch, y:y_batch, L:L_batch, training:True})\n",
    "          if epoch % 5 == 0:\n",
    "               loss_batch, acc_batch = sess.run([loss, accuracy], feed_dict={X:X_batch, y:y_batch, L:L_batch})\n",
    "               loss_test, acc_test = sess.run([loss, accuracy], feed_dict={X:X_test, y:y_test, L:L_test})\n",
    "               print epoch, loss_batch, acc_batch, loss_test, acc_test\n",
    "     #Lu = embed.eval(feed_dict={X:[[123, 19, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if zero padding is necessary for small case with sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_batch, y_batch, L_batch = fetch_batch(X_training, y_training, L_training, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4748, 2450, 9473, ...,    0,    0,    0],\n",
       "       [8236, 8173, 3847, ...,    0,    0,    0],\n",
       "       [1130, 9434, 2122, ...,    0,    0,    0],\n",
       "       ..., \n",
       "       [2925, 1569, 7522, ...,    0,    0,    0],\n",
       "       [4748, 7113, 4964, ...,    0,    0,    0],\n",
       "       [2925, 1089, 8559, ..., 4108,    0,    0]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  6, 12, 13, 15, 14, 14, 13,  5,  8,  5, 13, 14,  6,  8, 15,  9,\n",
       "        7, 10, 10,  9, 15, 10,  9,  8,  7, 10,  7, 12, 14,  7,  6, 10,  9,\n",
       "        5, 12, 12, 13, 13,  9, 11,  5,  6, 12, 11, 13,  6,  7, 13, 12,  8,\n",
       "        6,  6, 15, 14, 15, 15, 15,  6, 15,  6,  6, 13, 12, 13, 10,  8, 10,\n",
       "       10,  5, 11, 15,  6,  7, 13])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 15)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59027500996412918"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestClassifier(n_estimators=25).fit(X_training, y_training).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model doesn't make much sense given the zero padding."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
