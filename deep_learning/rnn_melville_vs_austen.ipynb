{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jonathan Halverson\n",
    "# Wednesday, January 17, 2018\n",
    "# Melville versus Austen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we train an RNN to classify sentences as written by either Melville or Jane Austen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('halverson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the two books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "melville_raw = list(nltk.corpus.gutenberg.words('melville-moby_dick.txt'))\n",
    "austen_raw = list(nltk.corpus.gutenberg.words('austen-sense.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "melville = melville_raw[melville_raw.index('Ishmael') - 2:]\n",
    "austen = austen_raw[austen_raw.index('The'):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_sentences(x):\n",
    "     j = ' '.join(x).replace('Mr .', 'Mr').replace('Mrs .', 'Mrs')\n",
    "     j = j.replace('Ms .', 'Ms').replace('Dr .', 'Dr')\n",
    "     j = j.replace('?', '.').replace('!', '.')\n",
    "     return j.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Call me Ishmael ',\n",
       " u' Some years ago -- never mind how long precisely -- having little or no money in my purse , and nothing particular to interest me on shore , I thought I would sail about a little and see the watery part of the world ',\n",
       " u' It is a way I have of driving off the spleen and regulating the circulation ',\n",
       " u\" Whenever I find myself growing grim about the mouth ; whenever it is a damp , drizzly November in my soul ; whenever I find myself involuntarily pausing before coffin warehouses , and bringing up the rear of every funeral I meet ; and especially whenever my hypos get such an upper hand of me , that it requires a strong moral principle to prevent me from deliberately stepping into the street , and methodically knocking people ' s hats off -- then , I account it high time to get to sea as soon as I can \",\n",
       " u' This is my substitute for pistol and ball ',\n",
       " u' With a philosophical flourish Cato throws himself upon his sword ; I quietly take to the ship ',\n",
       " u' There is nothing surprising in this ',\n",
       " u' If they but knew it , almost all men in their degree , some time or other , cherish very nearly the same feelings towards the ocean with me ',\n",
       " u' There now is your insular city of the Manhattoes , belted round by wharves as Indian isles by coral reefs -- commerce surrounds it with her surf ',\n",
       " u' Right and left , the streets take you waterward ']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_sentences(melville)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'The family of Dashwood had long been settled in Sussex ',\n",
       " u' Their estate was large , and their residence was at Norland Park , in the centre of their property , where , for many generations , they had lived in so respectable a manner as to engage the general good opinion of their surrounding acquaintance ',\n",
       " u' The late owner of this estate was a single man , who lived to a very advanced age , and who for many years of his life , had a constant companion and housekeeper in his sister ',\n",
       " u' But her death , which happened ten years before his own , produced a great alteration in his home ; for to supply her loss , he invited and received into his house the family of his nephew Mr Henry Dashwood , the legal inheritor of the Norland estate , and the person to whom he intended to bequeath it ',\n",
       " u\" In the society of his nephew and niece , and their children , the old Gentleman ' s days were comfortably spent \",\n",
       " u' His attachment to them all increased ',\n",
       " u' The constant attention of Mr and Mrs Henry Dashwood to his wishes , which proceeded not merely from interest , but from goodness of heart , gave him every degree of solid comfort which his age could receive ; and the cheerfulness of the children added a relish to his existence ',\n",
       " u' By a former marriage , Mr Henry Dashwood had one son : by his present lady , three daughters ',\n",
       " u' The son , a steady respectable young man , was amply provided for by the fortune of his mother , which had been large , and half of which devolved on him on his coming of age ',\n",
       " u' By his own marriage , likewise , which happened soon afterwards , he added to his wealth ']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_sentences(austen)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def tokenize(raw_text):\n",
    "     # keep only alphabetical characters and split on whitespace\n",
    "     letters_only = re.sub(\"[^a-zA-Z]\", \" \", raw_text)\n",
    "     words = letters_only.lower().split()\n",
    "    \n",
    "     # count the words and filter based on count and stopwords, apply stemming\n",
    "     count = Counter(words)\n",
    "     #porter = PorterStemmer()\n",
    "     #stops = stopwords.words(\"english\")\n",
    "     #words = [porter.stem(word) for word in words if (word not in stops) and (count[word] > 1) and (len(word) > 1)]\n",
    "     words = [word for word in words if (count[word] > 0) and (len(word) > 1)]\n",
    "\n",
    "     return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16672"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = tokenize(' '.join(md))\n",
    "len(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205697"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('text8_moby_dick', 'w') as f:\n",
    "     f.write(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'in',\n",
       " u'her',\n",
       " u'search',\n",
       " u'after',\n",
       " u'her',\n",
       " u'missing',\n",
       " u'children',\n",
       " u'only',\n",
       " u'found',\n",
       " u'another']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'the', 14175),\n",
       " (u'of', 6469),\n",
       " (u'and', 6325),\n",
       " (u'to', 4539),\n",
       " (u'in', 4077),\n",
       " (u'that', 3045),\n",
       " (u'it', 2497),\n",
       " (u'his', 2495),\n",
       " (u'he', 1876),\n",
       " (u'but', 1805),\n",
       " (u'as', 1720),\n",
       " (u'with', 1692),\n",
       " (u'is', 1690),\n",
       " (u'was', 1627),\n",
       " (u'for', 1593),\n",
       " (u'all', 1515),\n",
       " (u'this', 1382),\n",
       " (u'at', 1304),\n",
       " (u'by', 1175),\n",
       " (u'whale', 1150),\n",
       " (u'not', 1142),\n",
       " (u'from', 1072),\n",
       " (u'him', 1058),\n",
       " (u'so', 1053),\n",
       " (u'on', 1040),\n",
       " (u'be', 1032),\n",
       " (u'one', 907),\n",
       " (u'you', 884),\n",
       " (u'there', 854),\n",
       " (u'now', 779),\n",
       " (u'had', 767),\n",
       " (u'have', 754),\n",
       " (u'or', 689),\n",
       " (u'were', 677),\n",
       " (u'they', 649),\n",
       " (u'like', 639),\n",
       " (u'me', 630)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count.most_common(37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary = dict()\n",
    "for word, _ in count.most_common(): # loop over all words in vocabulary\n",
    "     dictionary[word] = len(dictionary) # each word is assigned a unique id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# form running list of id's\n",
    "data = list()\n",
    "for word in words:\n",
    "     index = dictionary[word]\n",
    "     data.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inverted_dict = dict(zip(dictionary.values(), dictionary.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Sample data', [397, 36, 1007, 40, 241, 600, 134, 283, 105, 77], [u'call', u'me', u'ishmael', u'some', u'years', u'ago', u'never', u'mind', u'how', u'long'])\n"
     ]
    }
   ],
   "source": [
    "print('Sample data', data[:10], [inverted_dict[i] for i in data[:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word 'me' is the 37-th most common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "embedding_size = 128  # Dimension of the embedding vector.\n",
    "skip_window = 1       # How many words to consider left and right.\n",
    "num_skips = 2         # How many times to reuse an input to generate a label.\n",
    "num_sampled = 64      # Number of negative examples to sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = len(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_size = 16     # Random set of words to evaluate similarity on.\n",
    "valid_window = 100  # Only pick dev samples in the head of the distribution.\n",
    "valid_examples = np.random.choice(valid_window, valid_size, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = tf.Variable(tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "std = 1.0 / np.sqrt(embedding_size)\n",
    "nce_weights = tf.Variable(tf.truncated_normal([vocab_size, embedding_size], stddev=std))\n",
    "nce_biases = tf.Variable(tf.zeros([vocab_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "valid_dataset = tf.constant(valid_examples, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed = tf.nn.embedding_lookup(embeddings, train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.nce_loss(weights=nce_weights, biases=nce_biases, labels=train_labels,\n",
    "                                     inputs=embed, num_sampled=num_sampled, num_classes=vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1.0).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the cosine similarity between minibatch examples and all embeddings.\n",
    "norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n",
    "normalized_embeddings = embeddings / norm\n",
    "valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings, valid_dataset)\n",
    "similarity = tf.matmul(valid_embeddings, normalized_embeddings, transpose_b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_batch():\n",
    "     return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-32-178ea3fb6027>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-32-178ea3fb6027>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    for inputs, labels in generate_batch(...):\u001b[0m\n\u001b[0m                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "     init.run()\n",
    "     for inputs, labels in generate_batch(...):\n",
    "          feed_dict = {train_inputs: inputs, train_labels: labels}\n",
    "          _, cur_loss = session.run([optimizer, loss], feed_dict=feed_dict)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
