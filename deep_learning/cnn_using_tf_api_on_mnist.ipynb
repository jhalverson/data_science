{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jonathan Halverson\n",
    "# Friday, November 24, 2017\n",
    "# CNN on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we write our own CNN to predict on MNIST. Note that this is a simple example in comparison to the best performing models of the day which tend to be very deep yet efficient with respect to the number of parameters (e.g., ResNet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('/tmp/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 200\n",
    "X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "X_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to reshape the data for a 2-d convolutional net:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10679a290>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n01XvTXV+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11bd70710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_batch = X_batch.reshape(batch_size, 28, 28, 1)\n",
    "single_digit = X_batch[42, :, :, 0]\n",
    "plt.imshow(single_digit, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_digit.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_valid = mnist.validation.images\n",
    "y_valid = mnist.validation.labels\n",
    "X_test = mnist.test.images\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('inputs'):\n",
    "     X = tf.placeholder(dtype=tf.float32, shape=(None, 28 * 28), name=\"X\")\n",
    "     X_reshaped = tf.reshape(X, shape=[-1, 28, 28, 1])\n",
    "     y = tf.placeholder(dtype=tf.int64, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_1 = tf.layers.conv2d(X_reshaped, filters=10, kernel_size=7, strides=[2, 2], padding=\"SAME\", activation=tf.nn.relu)\n",
    "max_pool_1 = tf.nn.max_pool(conv_1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "conv_2 = tf.layers.conv2d(max_pool_1, filters=5, kernel_size=2, strides=[2, 2], padding=\"SAME\", activation=tf.nn.relu)\n",
    "max_pool_2 = tf.nn.max_pool(conv_2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "\n",
    "with tf.name_scope(\"fc1\"):\n",
    "     full_1 = tf.layers.dense(tf.reshape(max_pool_2, shape=[-1, 20]), units=50, activation=tf.nn.relu)\n",
    "\n",
    "with tf.name_scope(\"output\"):\n",
    "     logits = tf.layers.dense(full_1, units=10, activation=None, name='outputs')\n",
    "     Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "     xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "     loss = tf.reduce_mean(xentropy, name='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9, use_nesterov=True)\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "cm = tf.confusion_matrix(y, tf.arg_max(logits, dimension=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 train: 0.3 valid: 0.2948\n",
      "10 train: 0.9 valid: 0.9036\n",
      "20 train: 0.95 valid: 0.9424\n",
      "30 train: 0.965 valid: 0.9496\n",
      "40 train: 0.93 valid: 0.9558\n",
      "50 train: 0.945 valid: 0.9598\n",
      "60 train: 0.93 valid: 0.9612\n",
      "70 train: 0.97 valid: 0.9644\n",
      "80 train: 0.95 valid: 0.9664\n",
      "90 train: 0.96 valid: 0.9684\n",
      "train (entire): 0.967182\n",
      "test: 0.9674\n",
      "CM:\n",
      "[[ 965    0    1    2    1    5    0    2    4    0]\n",
      " [   0 1127    3    3    0    0    0    1    1    0]\n",
      " [   6    3  998    8    4    0    1    3    8    1]\n",
      " [   4    0    9  969    0   14    0    6    4    4]\n",
      " [   1    0    5    0  956    0    1    0    3   16]\n",
      " [   3    0    0    7    0  868    4    0    7    3]\n",
      " [   6    4    6    0    6    7  924    0    5    0]\n",
      " [   2    6   13    1    1    0    0  987    4   14]\n",
      " [   3    2    9    9    3    3    3    5  929    8]\n",
      " [   6    5    4    5   17    6    0   13    2  951]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "     init.run()\n",
    "     for epoch in xrange(n_epochs):\n",
    "          for iteration in range(mnist.train.num_examples // batch_size):\n",
    "               X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "               sess.run(training_op, feed_dict={X:X_batch, y:y_batch})\n",
    "          if (epoch % 10 == 0):\n",
    "               print epoch, \"train:\", accuracy.eval(feed_dict={X:X_batch, y:y_batch}), \\\n",
    "                            \"valid:\", accuracy.eval(feed_dict={X:X_valid, y:y_valid})\n",
    "     print \"train (entire):\", accuracy.eval(feed_dict={X:mnist.train.images, y:mnist.train.labels})\n",
    "     print \"test:\", accuracy.eval(feed_dict={X:X_test, y:y_test})\n",
    "     print \"CM:\\n\", cm.eval(feed_dict={X:X_test, y:y_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we consider Geron's solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geron uses two successive convolutional layers, dropout and early stopping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "height = 28\n",
    "width = 28\n",
    "channels = 1\n",
    "n_inputs = height * width\n",
    "\n",
    "conv1_fmaps = 32\n",
    "conv1_ksize = 3\n",
    "conv1_stride = 1\n",
    "conv1_pad = \"SAME\"\n",
    "\n",
    "conv2_fmaps = 64\n",
    "conv2_ksize = 3\n",
    "conv2_stride = 1\n",
    "conv2_pad = \"SAME\"\n",
    "conv2_dropout_rate = 0.25\n",
    "\n",
    "pool3_fmaps = conv2_fmaps\n",
    "\n",
    "n_fc1 = 128\n",
    "fc1_dropout_rate = 0.5\n",
    "\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"inputs\"):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_inputs], name=\"X\")\n",
    "    X_reshaped = tf.reshape(X, shape=[-1, height, width, channels])\n",
    "    y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
    "    training = tf.placeholder_with_default(False, shape=[], name='training')\n",
    "\n",
    "conv1 = tf.layers.conv2d(X_reshaped, filters=conv1_fmaps, kernel_size=conv1_ksize,\n",
    "                         strides=conv1_stride, padding=conv1_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv1\")\n",
    "conv2 = tf.layers.conv2d(conv1, filters=conv2_fmaps, kernel_size=conv2_ksize,\n",
    "                         strides=conv2_stride, padding=conv2_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv2\")\n",
    "\n",
    "with tf.name_scope(\"pool3\"):\n",
    "    pool3 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "    pool3_flat = tf.reshape(pool3, shape=[-1, pool3_fmaps * 14 * 14])\n",
    "    pool3_flat_drop = tf.layers.dropout(pool3_flat, conv2_dropout_rate, training=training)\n",
    "\n",
    "with tf.name_scope(\"fc1\"):\n",
    "    fc1 = tf.layers.dense(pool3_flat_drop, n_fc1, activation=tf.nn.relu, name=\"fc1\")\n",
    "    fc1_drop = tf.layers.dropout(fc1, fc1_dropout_rate, training=training)\n",
    "\n",
    "with tf.name_scope(\"output\"):\n",
    "    logits = tf.layers.dense(fc1, n_outputs, name=\"output\")\n",
    "    Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "with tf.name_scope(\"init_and_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_params():\n",
    "    gvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "    return {gvar.op.name: value for gvar, value in zip(gvars, tf.get_default_session().run(gvars))}\n",
    "\n",
    "def restore_model_params(model_params):\n",
    "    gvar_names = list(model_params.keys())\n",
    "    assign_ops = {gvar_name: tf.get_default_graph().get_operation_by_name(gvar_name + \"/Assign\")\n",
    "                  for gvar_name in gvar_names}\n",
    "    init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op in assign_ops.items()}\n",
    "    feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}\n",
    "    tf.get_default_session().run(assign_ops, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 50\n",
    "\n",
    "best_loss_val = np.infty\n",
    "check_interval = 500\n",
    "checks_since_last_progress = 0\n",
    "max_checks_without_progress = 20\n",
    "best_model_params = None \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X:X_batch, y:y_batch, training: True})\n",
    "            if iteration % check_interval == 0:\n",
    "                loss_val = loss.eval(feed_dict={X:X_batch, y:y_batch})\n",
    "               \n",
    "                if loss_val < best_loss_val:\n",
    "                    best_loss_val = loss_val\n",
    "                    checks_since_last_progress = 0\n",
    "                    best_model_params = get_model_params()\n",
    "                else:\n",
    "                    checks_since_last_progress += 1\n",
    "        acc_train = accuracy.eval(feed_dict={X:X_batch, y:y_batch})\n",
    "        acc_val = accuracy.eval(feed_dict={X:X_valid, y:y_valid})\n",
    "        print(\"Epoch {}, train accuracy: {:.4f}%, valid. accuracy: {:.4f}%, valid. best loss: {:.6f}\".format(epoch, acc_train * 100, acc_val * 100, best_loss_val))\n",
    "        if checks_since_last_progress > max_checks_without_progress:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "    if best_model_params:\n",
    "        restore_model_params(best_model_params)\n",
    "    acc_test = accuracy.eval(feed_dict={X:X_test, y:y_test})\n",
    "    print(\"Final accuracy on test set:\", acc_test)\n",
    "    save_path = saver.save(sess, \"./my_mnist_model\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
