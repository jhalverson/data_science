{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jonathan Halverson\n",
    "# Friday, November 24, 2017\n",
    "# CNN on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('/tmp/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 200\n",
    "X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "X_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to reshape the data for a 2-d convolutional net:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x105e33050>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADZ5JREFUeJzt3X+MFPUZx/HP41liFEKwTfGEa8FIagh/ULwQE6GhsRBE\nEiQxROIf1KJnDDZtokkN/aOapgk2paZ/KIYGLG1aoEYNhJgSJU3VRJDTtP44W8DmSrnwQ4MJNhEE\n7+kfO9dc9fY7y87szh7P+5VcbneenZmHDZ+bnf3uztfcXQDiuazqBgBUg/ADQRF+ICjCDwRF+IGg\nCD8QFOEHgiL8QFCEHwjq8nbuzMz4OCHQYu5ujTyu0JHfzJaa2T/M7IiZPVxkWwDay5r9bL+ZdUk6\nJGmxpGOSDkpa7e4DiXU48gMt1o4j/3xJR9z9n+7+qaQdklYU2B6ANioS/mmS/j3q/rFs2f8xsz4z\n6zez/gL7AlCylr/h5+6bJW2WeNkPdJIiR/4hST2j7k/PlgEYB4qE/6CkWWY208wmSLpT0u5y2gLQ\nak2/7Hf3C2b2gKS9krokbXX3d0vrDEBLNT3U19TOOOcHWq4tH/IBMH4RfiAowg8ERfiBoAg/EBTh\nB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QVFsv3Q2Mtnjx4mT9+uuvL7T95cuX163ddttthbZ9\nKeDIDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBMc6PQrq7u5P1p59+um5t/vz5yXUnT57cVE8jzp8/\nX7e2du3a5LpbtmwptO/xgCM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRVaJzfzAYlfSzpM0kX3L23\njKbQPl1dXcn6xIkTk/Vdu3Yl6zfeeONF9zTi3LlzyfrZs2eT9SeeeKJu7bXXXmuqp0tJGR/y+ba7\nf1jCdgC0ES/7gaCKht8lvWRmb5hZXxkNAWiPoi/7F7j7kJl9VdKLZvZ3d3959AOyPwr8YQA6TKEj\nv7sPZb9PSXpe0he+qeHum929lzcDgc7SdPjN7CozmzRyW9ISSe+U1RiA1irysn+qpOfNbGQ7f3D3\nP5XSFYCWM3dv387M2rczNOSaa65J1vfs2ZOsz5s3L1lP/f/KG8dfuXJlsr53795kPSp3t0Yex1Af\nEBThB4Ii/EBQhB8IivADQRF+ICgu3R3cwoULk/VZs2a1bN/9/f3JOkN5rcWRHwiK8ANBEX4gKMIP\nBEX4gaAIPxAU4QeCYpz/Erdo0aJkfdOmTcl63qW787z66qt1a6tXry60bRTDkR8IivADQRF+ICjC\nDwRF+IGgCD8QFOEHgmKc/xKwdOnSurX7778/ue6UKVMK7fvAgQPJ+h133FG39sEHHxTaN4rhyA8E\nRfiBoAg/EBThB4Ii/EBQhB8IivADQeVO0W1mWyUtl3TK3edky66WtFPSDEmDkla5+0e5O2OK7qb0\n9PQk64cOHapbmzBhQqF9P/jgg8n6U089layfPXu20P5x8cqcovs3kj7/KZKHJe1z91mS9mX3AYwj\nueF395clnf7c4hWStmW3t0m6veS+ALRYs+f8U939eHb7hKSpJfUDoE0Kf7bf3T11Lm9mfZL6iu4H\nQLmaPfKfNLNuScp+n6r3QHff7O697t7b5L4AtECz4d8taU12e42kXeW0A6BdcsNvZtslvSbpG2Z2\nzMzWStogabGZHZb0new+gHEk95zf3etdXP2WkntBHdOmTUvWi4zlv//++8n6jh07knXG8ccvPuEH\nBEX4gaAIPxAU4QeCIvxAUIQfCIpLd3eAOXPmJOvbt29v2b63bt2arJ84caJl+0a1OPIDQRF+ICjC\nDwRF+IGgCD8QFOEHgiL8QFC5l+4udWdcuntMR48eTdanT5/e9LYPHz6crC9btixZz/vKLzpPmZfu\nBnAJIvxAUIQfCIrwA0ERfiAowg8ERfiBoPg+fwcYHh5O1ot8FuP1119P1ls9jj9v3ry6tbxLju/f\nv7/sdjAKR34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCCp3nN/MtkpaLumUu8/Jlj0i6V5JH2QPW+/u\nL7SqSTTvk08+Sda7urqS9XvvvTdZX7hwYbJ+66231q1deeWVyXWfeeaZZH1gYCBZf/LJJ+vWzp07\nl1w3wtTjjRz5fyNp6RjLH3f3udkPwQfGmdzwu/vLkk63oRcAbVTknP/7ZvaWmW01symldQSgLZoN\n/yZJ10maK+m4pI31HmhmfWbWb2b9Te4LQAs0FX53P+nun7n7sKRfS5qfeOxmd+91995mmwRQvqbC\nb2bdo+6ulPROOe0AaJdGhvq2S1ok6StmdkzSTyQtMrO5klzSoKT7WtgjgBbguv0dYHBwMFnv6elp\nettTpqTfi73vvvTf7Q0bNiTrZulLxLfz/9fFWL9+fbL+2GOPtamT8nHdfgBJhB8IivADQRF+ICjC\nDwRF+IGguHR3G6xbty5Zv/baawttPzUcd8sttyTXffTRRwvtG+MXR34gKMIPBEX4gaAIPxAU4QeC\nIvxAUIQfCIpx/jaYNGlSsp53+ew8qa/VHjx4MLlu3hTds2fPbqqnEUeOHKlbe/zxx5PrLlmyJFlf\nsWJFsn7hwoW6tTNnziTXjYAjPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ExaW72+Cmm25K1l94IT3J\n8eTJk5ve9913352s33PPPcn6zTffnKx38qW7jx49Wrc2c+bMNnbSXly6G0AS4QeCIvxAUIQfCIrw\nA0ERfiAowg8ElTvOb2Y9kn4raaokl7TZ3X9lZldL2ilphqRBSavc/aOcbYUc58/Tyim6z58/n6xf\ndln673/etQby1h8eHk7WixgaGkrWV61aVbe2f//+stvpGGWO81+Q9KC7z5Z0k6R1ZjZb0sOS9rn7\nLEn7svsAxonc8Lv7cXd/M7v9saT3JE2TtELStuxh2yTd3qomAZTvos75zWyGpG9KOiBpqrsfz0on\nVDstADBONHwNPzObKOlZST909zOjP9Pt7l7vfN7M+iT1FW0UQLkaOvKb2ZdUC/7v3f25bPFJM+vO\n6t2STo21rrtvdvded+8to2EA5cgNv9UO8VskvefuvxxV2i1pTXZ7jaRd5bcHoFUaGepbIOkVSW9L\nGhm3Wa/aef8fJX1N0r9UG+o7nbMthvrGkPe124ceeihZv+GGG8ps56LkfaX30KFDdWsffZQcGc79\nd+etPzAwkKxfqhod6ss953f3VyXV21h68ncAHYtP+AFBEX4gKMIPBEX4gaAIPxAU4QeC4tLd40De\nFN933XVX3drGjRuT615xxRVN9TTigQceSNZ37txZt3b6dPJjIWgSl+4GkET4gaAIPxAU4QeCIvxA\nUIQfCIrwA0Exzg9cYhjnB5BE+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeC\nIvxAUIQfCIrwA0Hlht/Meszsz2Y2YGbvmtkPsuWPmNmQmf01+1nW+nYBlCX3Yh5m1i2p293fNLNJ\nkt6QdLukVZL+4+6/aHhnXMwDaLlGL+ZxeQMbOi7peHb7YzN7T9K0Yu0BqNpFnfOb2QxJ35R0IFv0\nfTN7y8y2mtmUOuv0mVm/mfUX6hRAqRq+hp+ZTZT0F0k/c/fnzGyqpA8luaSfqnZq8L2cbfCyH2ix\nRl/2NxR+M/uSpD2S9rr7L8eoz5C0x93n5GyH8AMtVtoFPM3MJG2R9N7o4GdvBI5YKemdi20SQHUa\nebd/gaRXJL0taThbvF7SaklzVXvZPyjpvuzNwdS2OPIDLVbqy/6yEH6g9bhuP4Akwg8ERfiBoAg/\nEBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFC5F/As2YeS/jXq/leyZZ2oU3vr\n1L4kemtWmb19vdEHtvX7/F/YuVm/u/dW1kBCp/bWqX1J9NasqnrjZT8QFOEHgqo6/Jsr3n9Kp/bW\nqX1J9NasSnqr9JwfQHWqPvIDqEgl4TezpWb2DzM7YmYPV9FDPWY2aGZvZzMPVzrFWDYN2ikze2fU\nsqvN7EUzO5z9HnOatIp664iZmxMzS1f63HXajNdtf9lvZl2SDklaLOmYpIOSVrv7QFsbqcPMBiX1\nunvlY8Jm9i1J/5H025HZkMzs55JOu/uG7A/nFHf/UYf09ogucubmFvVWb2bp76rC567MGa/LUMWR\nf76kI+7+T3f/VNIOSSsq6KPjufvLkk5/bvEKSduy29tU+8/TdnV66wjuftzd38xufyxpZGbpSp+7\nRF+VqCL80yT9e9T9Y+qsKb9d0ktm9oaZ9VXdzBimjpoZ6YSkqVU2M4bcmZvb6XMzS3fMc9fMjNdl\n4w2/L1rg7nMl3SppXfbytiN57Zytk4ZrNkm6TrVp3I5L2lhlM9nM0s9K+qG7nxldq/K5G6OvSp63\nKsI/JKln1P3p2bKO4O5D2e9Tkp5X7TSlk5wcmSQ1+32q4n7+x91Puvtn7j4s6deq8LnLZpZ+VtLv\n3f25bHHlz91YfVX1vFUR/oOSZpnZTDObIOlOSbsr6OMLzOyq7I0YmdlVkpao82Yf3i1pTXZ7jaRd\nFfbyfzpl5uZ6M0ur4ueu42a8dve2/0hapto7/u9L+nEVPdTp6zpJf8t+3q26N0nbVXsZeF6190bW\nSvqypH2SDkt6SdLVHdTb71Sbzfkt1YLWXVFvC1R7Sf+WpL9mP8uqfu4SfVXyvPEJPyAo3vADgiL8\nQFCEHwiK8ANBEX4gKMIPBEX4gaAIPxDUfwGfgW91Qm5C4wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b65e6d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_batch = X_batch.reshape(batch_size, 28, 28, 1)\n",
    "single_digit = X_batch[42, :, :, 0]\n",
    "plt.imshow(single_digit, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_valid = mnist.validation.images.reshape(-1, 28, 28, 1)\n",
    "y_valid = mnist.validation.labels\n",
    "X_test = mnist.test.images.reshape(-1, 28, 28, 1)\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(dtype=tf.float32, shape=(None, 28, 28, 1), name=\"X\")\n",
    "y = tf.placeholder(dtype=tf.int64, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_1 = tf.layers.conv2d(X, filters=10, kernel_size=7, strides=[2, 2], padding=\"SAME\", activation=tf.nn.relu)\n",
    "max_pool_1 = tf.nn.max_pool(conv_1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "conv_2 = tf.layers.conv2d(max_pool_1, filters=5, kernel_size=2, strides=[2, 2], padding=\"SAME\", activation=tf.nn.relu)\n",
    "max_pool_2 = tf.nn.max_pool(conv_2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "logits = tf.layers.dense(tf.reshape(max_pool_2, [-1, 20]), units=10, activation=None, name='outputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "     init.run()\n",
    "     X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "     X_batch = X_batch.reshape(batch_size, 28, 28, 1)\n",
    "     output = logits.eval(feed_dict={X:X_batch, y:y_batch})\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "     xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "     loss = tf.reduce_mean(xentropy, name='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9, use_nesterov=True)\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "cm = tf.confusion_matrix(y, tf.arg_max(logits, dimension=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "n_epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 train: 0.2734\n",
      "1 train: 0.3464\n",
      "2 train: 0.4804\n",
      "3 train: 0.6262\n",
      "4 train: 0.714\n",
      "5 train: 0.7788\n",
      "6 train: 0.815\n",
      "7 train: 0.842\n",
      "8 train: 0.8588\n",
      "9 train: 0.8704\n",
      "10 train: 0.8842\n",
      "11 train: 0.8926\n",
      "12 train: 0.8974\n",
      "13 train: 0.9018\n",
      "14 train: 0.906\n",
      "test: 0.9078\n",
      "CM: [[ 941    0    4    3    2    6   18    2    3    1]\n",
      " [   0 1109    6    4    2    0    6    1    7    0]\n",
      " [  13    7  895   31   16    2   12   20   31    5]\n",
      " [   6    1   23  897    1   32    2    8   31    9]\n",
      " [   3    7    4    3  900    0    9    2    5   49]\n",
      " [   8    2    3   51    2  777    7    1   30   11]\n",
      " [  25    6    7    0   10   16  884    0   10    0]\n",
      " [   9   11   34    8    7    3    0  926    3   27]\n",
      " [   8   12    8   21    4   14    8    8  867   24]\n",
      " [  16    8    8    7   39    6    1   28   14  882]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "     init.run()\n",
    "     for epoch in xrange(n_epochs):\n",
    "          for iteration in range(mnist.train.num_examples // batch_size):\n",
    "               X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "               X_batch = X_batch.reshape(-1, 28, 28, 1)\n",
    "               sess.run(training_op, feed_dict={X:X_batch, y:y_batch})\n",
    "          print epoch, \"train:\", accuracy.eval(feed_dict={X:X_valid, y:y_valid})\n",
    "     print \"test:\", accuracy.eval(feed_dict={X:X_test, y:y_test})\n",
    "     print \"CM:\\n\", cm.eval(feed_dict={X:X_test, y:y_test})"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
