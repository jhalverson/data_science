{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jonathan Halverson\n",
    "# Tuesday, December 27, 2016\n",
    "# Wine classification in Spark 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we work a standard machine learning binary classification problem with the twist that we split the three class records between the 0 and 1 class so that the classifier isn't very good and we can examine its performance. For the EDA see the appropriate notebook in the machine_learning directory.\n",
    "\n",
    "Here is a nice notebook by Ben Sadeghi on a related topic:\n",
    "http://nbviewer.jupyter.org/github/bensadeghi/pyspark-churn-prediction/blob/master/churn-prediction.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[4]\").appName(\"Wine classification\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+----+----+---+----+----+----+----+----+----+----+----+\n",
      "|_c0|  _c1| _c2| _c3| _c4|_c5| _c6| _c7| _c8| _c9|_c10|_c11|_c12|_c13|\n",
      "+---+-----+----+----+----+---+----+----+----+----+----+----+----+----+\n",
      "|  1|13.77| 1.9|2.68|17.1|115| 3.0|2.79|0.39|1.68| 6.3|1.13|2.93|1375|\n",
      "|  1|13.72|1.43| 2.5|16.7|108| 3.4|3.67|0.19|2.04| 6.8|0.89|2.87|1285|\n",
      "|  2|12.33| 1.1|2.28|16.0|101|2.05|1.09|0.63|0.41|3.27|1.25|1.67| 680|\n",
      "|  2|11.96|1.09| 2.3|21.0|101|3.38|2.14|0.13|1.65|3.21|0.99|3.13| 886|\n",
      "|  2|11.84|0.89|2.58|18.0| 94| 2.2|2.21|0.22|2.35|3.05|0.79|3.08| 520|\n",
      "|  2|12.08|1.33| 2.3|23.6| 70| 2.2|1.59|0.42|1.38|1.74|1.07|3.21| 625|\n",
      "|  2| 12.0|3.43| 2.0|19.0| 87| 2.0|1.64|0.37|1.87|1.28|0.93|3.05| 564|\n",
      "|  2|12.42|4.43|2.73|26.5|102| 2.2|2.13|0.43|1.71|2.08|0.92|3.12| 365|\n",
      "|  2|11.79|2.13|2.78|28.5| 92|2.13|2.24|0.58|1.76| 3.0|0.97|2.44| 466|\n",
      "|  3|12.25|4.72|2.54|21.0| 89|1.38|0.47|0.53| 0.8|3.85|0.75|1.27| 720|\n",
      "|  3|13.52|3.17|2.72|23.5| 97|1.55|0.52| 0.5|0.55|4.35|0.89|2.06| 520|\n",
      "|  3|13.73|4.36|2.26|22.5| 88|1.28|0.47|0.52|1.15|6.62|0.78|1.75| 520|\n",
      "|  3|14.16|2.51|2.48|20.0| 91|1.68| 0.7|0.44|1.24| 9.7|0.62|1.71| 660|\n",
      "+---+-----+----+----+----+---+----+----+----+----+----+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('../../machine_learning/wine.csv', header=False, inferSchema=True)\n",
    "df.sample(False, 0.1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- _c1: double (nullable = true)\n",
      " |-- _c2: double (nullable = true)\n",
      " |-- _c3: double (nullable = true)\n",
      " |-- _c4: double (nullable = true)\n",
      " |-- _c5: integer (nullable = true)\n",
      " |-- _c6: double (nullable = true)\n",
      " |-- _c7: double (nullable = true)\n",
      " |-- _c8: double (nullable = true)\n",
      " |-- _c9: double (nullable = true)\n",
      " |-- _c10: double (nullable = true)\n",
      " |-- _c11: double (nullable = true)\n",
      " |-- _c12: double (nullable = true)\n",
      " |-- _c13: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class labels must begin with 0 and count up in Spark. Here we will only consider a binary classification problem so we randomly assign class 3 to the other classes -- this will lead to mistakes by the classifier which will allow for a interesting validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "from random import random as rng\n",
    "from random import seed\n",
    "\n",
    "seed(123456)\n",
    "def randomFlip3rd(x):\n",
    "    if (x == 3):\n",
    "        if (rng() > 0.5):\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        return x - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trans3rd = udf(randomFlip3rd, IntegerType())\n",
    "df = df.withColumn('_c0', trans3rd(df._c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+----+----+---+----+----+----+----+-----+----+----+----+\n",
      "|_c0|  _c1| _c2| _c3| _c4|_c5| _c6| _c7| _c8| _c9| _c10|_c11|_c12|_c13|\n",
      "+---+-----+----+----+----+---+----+----+----+----+-----+----+----+----+\n",
      "|  0|13.63|1.81| 2.7|17.2|112|2.85|2.91| 0.3|1.46|  7.3|1.28|2.88|1310|\n",
      "|  0| 13.5|1.81|2.61|20.0| 96|2.53|2.61|0.28|1.66| 3.52|1.12|3.82| 845|\n",
      "|  0|13.05|2.05|3.22|25.0|124|2.63|2.68|0.47|1.92| 3.58|1.13| 3.2| 830|\n",
      "|  0|13.87| 1.9| 2.8|19.4|107|2.95|2.97|0.37|1.76|  4.5|1.25| 3.4| 915|\n",
      "|  0|14.22| 1.7| 2.3|16.3|118| 3.2| 3.0|0.26|2.03| 6.38|0.94|3.31| 970|\n",
      "|  1|12.37|0.94|1.36|10.6| 88|1.98|0.57|0.28|0.42| 1.95|1.05|1.82| 520|\n",
      "|  1|12.99|1.67| 2.6|30.0|139| 3.3|2.89|0.21|1.96| 3.35|1.31| 3.5| 985|\n",
      "|  1|11.66|1.88|1.92|16.0| 97|1.61|1.57|0.34|1.15|  3.8|1.23|2.14| 428|\n",
      "|  1|12.08|1.13|2.51|24.0| 78| 2.0|1.58| 0.4| 1.4|  2.2|1.31|2.72| 630|\n",
      "|  1|12.16|1.61|2.31|22.8| 90|1.78|1.69|0.43|1.56| 2.45|1.33|2.26| 495|\n",
      "|  1|12.29|1.41|1.98|16.0| 85|2.55| 2.5|0.29|1.77|  2.9|1.23|2.74| 428|\n",
      "|  1|11.41|0.74| 2.5|21.0| 88|2.48|2.01|0.42|1.44| 3.08| 1.1|2.31| 434|\n",
      "|  1|11.82|1.47|1.99|20.8| 86|1.98| 1.6| 0.3|1.53| 1.95|0.95|3.33| 495|\n",
      "|  1| 12.0|3.43| 2.0|19.0| 87| 2.0|1.64|0.37|1.87| 1.28|0.93|3.05| 564|\n",
      "|  0| 12.7|3.55|2.36|21.5|106| 1.7| 1.2|0.17|0.84|  5.0|0.78|1.29| 600|\n",
      "|  0| 13.5|3.12|2.62|24.0|123| 1.4|1.57|0.22|1.25|  8.6|0.59| 1.3| 500|\n",
      "|  0|14.34|1.68| 2.7|25.0| 98| 2.8|1.31|0.53| 2.7| 13.0|0.57|1.96| 660|\n",
      "|  0|12.82|3.37| 2.3|19.5| 88|1.48|0.66| 0.4|0.97|10.26|0.72|1.75| 685|\n",
      "+---+-----+----+----+----+---+----+----+----+----+-----+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sample(False, 0.1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _c0  count\n",
       "0    1    101\n",
       "1    0     77"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('_c0').count().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the two classes appear with equal proportions so stratified sampling is not required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in local mode even with the [4] only one partition is being used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- _c1: double (nullable = true)\n",
      " |-- _c2: double (nullable = true)\n",
      " |-- _c3: double (nullable = true)\n",
      " |-- _c4: double (nullable = true)\n",
      " |-- _c5: integer (nullable = true)\n",
      " |-- _c6: double (nullable = true)\n",
      " |-- _c7: double (nullable = true)\n",
      " |-- _c8: double (nullable = true)\n",
      " |-- _c9: double (nullable = true)\n",
      " |-- _c10: double (nullable = true)\n",
      " |-- _c11: double (nullable = true)\n",
      " |-- _c12: double (nullable = true)\n",
      " |-- _c13: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change the data type of _c5 and _c13 to double:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- _c1: double (nullable = true)\n",
      " |-- _c2: double (nullable = true)\n",
      " |-- _c3: double (nullable = true)\n",
      " |-- _c4: double (nullable = true)\n",
      " |-- _c5: double (nullable = true)\n",
      " |-- _c6: double (nullable = true)\n",
      " |-- _c7: double (nullable = true)\n",
      " |-- _c8: double (nullable = true)\n",
      " |-- _c9: double (nullable = true)\n",
      " |-- _c10: double (nullable = true)\n",
      " |-- _c11: double (nullable = true)\n",
      " |-- _c12: double (nullable = true)\n",
      " |-- _c13: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('_c5', df['_c5'].cast('double'))\n",
    "df = df.withColumn('_c13', df['_c13'].cast('double'))\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give the columns more meaningful names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['Class', 'Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash', 'Magnesium', 'Total phenols', \\\n",
    "           'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue', \\\n",
    "           'OD280/OD315 of diluted wines', 'Proline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for u, v in zip(df.schema.names, columns):\n",
    "    df = df.withColumnRenamed(u, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Class: integer (nullable = true)\n",
      " |-- Alcohol: double (nullable = true)\n",
      " |-- Malic acid: double (nullable = true)\n",
      " |-- Ash: double (nullable = true)\n",
      " |-- Alcalinity of ash: double (nullable = true)\n",
      " |-- Magnesium: double (nullable = true)\n",
      " |-- Total phenols: double (nullable = true)\n",
      " |-- Flavanoids: double (nullable = true)\n",
      " |-- Nonflavanoid phenols: double (nullable = true)\n",
      " |-- Proanthocyanins: double (nullable = true)\n",
      " |-- Color intensity: double (nullable = true)\n",
      " |-- Hue: double (nullable = true)\n",
      " |-- OD280/OD315 of diluted wines: double (nullable = true)\n",
      " |-- Proline: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an alternative version of assigning the column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>18.8</td>\n",
       "      <td>103.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1060.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>17.4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>12.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>10.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>22.5</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>520.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Alcohol  Malic acid  Ash  Alcalinity of ash  Magnesium  \\\n",
       "0    0.0     14.1         2.0  2.4               18.8      103.0   \n",
       "1    0.0     13.9         1.7  2.3               17.4      108.0   \n",
       "2    1.0     12.8         3.4  2.0               16.0       80.0   \n",
       "3    0.0     12.8         2.7  2.5               22.0      112.0   \n",
       "4    0.0     13.7         4.4  2.3               22.5       88.0   \n",
       "\n",
       "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0            2.8         2.9                   0.3              2.4   \n",
       "1            2.9         3.5                   0.3              2.1   \n",
       "2            1.6         1.3                   0.4              0.8   \n",
       "3            1.5         1.4                   0.2              1.3   \n",
       "4            1.3         0.5                   0.5              1.1   \n",
       "\n",
       "   Color intensity  Hue  OD280/OD315 of diluted wines  Proline  \n",
       "0              6.2  1.1                           2.8   1060.0  \n",
       "1              8.9  1.1                           3.1   1260.0  \n",
       "2              3.4  0.7                           2.1    372.0  \n",
       "3             10.8  0.5                           1.5    480.0  \n",
       "4              6.6  0.8                           1.8    520.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wineRaw = reduce(lambda data, i: data.withColumnRenamed(df.schema.names[i], columns[i]), xrange(len(columns)), df)\n",
    "wineRaw.sample(False, 0.05).toPandas().applymap(lambda x: round(x, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the descriptive statistics -- of course, no standardization has been performed yet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>178.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>19.5</td>\n",
       "      <td>99.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>746.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>14.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>314.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>10.6</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>278.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>17.2</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>500.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>19.5</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>673.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>21.5</td>\n",
       "      <td>107.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>985.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.8</td>\n",
       "      <td>5.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1680.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Alcohol  Malic acid    Ash  Alcalinity of ash  Magnesium  \\\n",
       "count    178.0       178.0  178.0              178.0      178.0   \n",
       "mean      13.0         2.3    2.4               19.5       99.7   \n",
       "std        0.8         1.1    0.3                3.3       14.3   \n",
       "min       11.0         0.7    1.4               10.6       70.0   \n",
       "25%       12.4         1.6    2.2               17.2       88.0   \n",
       "50%       13.1         1.9    2.4               19.5       98.0   \n",
       "75%       13.7         3.1    2.6               21.5      107.0   \n",
       "max       14.8         5.8    3.2               30.0      162.0   \n",
       "\n",
       "       Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "count          178.0       178.0                 178.0            178.0   \n",
       "mean             2.3         2.0                   0.4              1.6   \n",
       "std              0.6         1.0                   0.1              0.6   \n",
       "min              1.0         0.3                   0.1              0.4   \n",
       "25%              1.7         1.2                   0.3              1.3   \n",
       "50%              2.4         2.1                   0.3              1.6   \n",
       "75%              2.8         2.9                   0.4              1.9   \n",
       "max              3.9         5.1                   0.7              3.6   \n",
       "\n",
       "       Color intensity    Hue  OD280/OD315 of diluted wines  Proline  \n",
       "count            178.0  178.0                         178.0    178.0  \n",
       "mean               5.1    1.0                           2.6    746.9  \n",
       "std                2.3    0.2                           0.7    314.9  \n",
       "min                1.3    0.5                           1.3    278.0  \n",
       "25%                3.2    0.8                           1.9    500.5  \n",
       "50%                4.7    1.0                           2.8    673.5  \n",
       "75%                6.2    1.1                           3.2    985.0  \n",
       "max               13.0    1.7                           4.0   1680.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wineRaw.select(wineRaw.schema.names[1:]).toPandas().describe().applymap(lambda x: round(x, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reformat the data into a new dataframe with features as a vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[2.87,1.04,13.24,...|    0|\n",
      "|[2.48,1.23,14.19,...|    0|\n",
      "|[2.56,0.96,13.64,...|    0|\n",
      "|[2.36,1.11,13.71,...|    0|\n",
      "|[2.8,1.25,13.87,2...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wineRaw = wineRaw.select('Class', 'Ash', 'Hue', 'Alcohol', 'Flavanoids').rdd.map(lambda row: Row(label=row.Class, features=Vectors.dense(row[1:]))).toDF()\n",
    "wineRaw.sample(False, 0.1).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the correct format, a train-test split can be performed before we standardize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainUnSTD, testUnSTD = wineRaw.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's standardize the data by making the mean and variance 0 and 1, respectively, for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=True, withMean=True)\n",
    "scalerModel = scaler.fit(trainUnSTD)\n",
    "train = scalerModel.transform(trainUnSTD).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- label: long (nullable = true)\n",
      " |-- scaledFeatures: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|            features|label|      scaledFeatures|\n",
      "+--------------------+-----+--------------------+\n",
      "|[1.36,1.05,12.37,...|    1|[-3.4963574389052...|\n",
      "|[1.7,1.12,13.11,3...|    1|[-2.3063143247853...|\n",
      "|[1.71,1.19,13.03,...|    1|[-2.2713130567230...|\n",
      "|[1.75,1.28,12.21,...|    1|[-2.1313079844736...|\n",
      "|[1.82,0.75,11.46,...|    1|[-1.8862991080371...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the standardized features have a mean of 0 and a variance of 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_1</th>\n",
       "      <th>_2</th>\n",
       "      <th>_3</th>\n",
       "      <th>_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.5</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>-1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          _1     _2     _3     _4\n",
       "count  130.0  130.0  130.0  130.0\n",
       "mean     0.0   -0.0   -0.0   -0.0\n",
       "std      1.0    1.0    1.0    1.0\n",
       "min     -3.5   -2.0   -2.4   -1.7\n",
       "25%     -0.6   -0.8   -0.8   -0.9\n",
       "50%      0.0    0.0    0.0    0.1\n",
       "75%      0.7    0.7    0.8    0.8\n",
       "max      3.0    3.3    1.9    3.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.rdd.map(lambda row: row.scaledFeatures.values.tolist()).toDF().toPandas().describe().applymap(lambda x: round(x, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the wine dataFrame is properly formatted, we create a ML model with cross-validation and hyperparameter optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(featuresCol='scaledFeatures', labelCol='label', maxIter=10, threshold=0.5)\n",
    "pipeline = Pipeline(stages=[lr])\n",
    "\n",
    "paramGrid = ParamGridBuilder().addGrid(lr.regParam, [1.0, 0.1, 0.01]).addGrid(lr.elasticNetParam, [1.0, 0.1, 0.01]).build()\n",
    "bce = BinaryClassificationEvaluator(metricName=\"areaUnderROC\")\n",
    "crossval = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=bce, numFolds=5)\n",
    "cvModel = crossval.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some details about the cross-validation procedure and the final coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5,\n",
       " 0.8788335275835276,\n",
       " 0.8845648795648796,\n",
       " 0.8771814296814296,\n",
       " 0.8836169386169386,\n",
       " 0.8892676767676768,\n",
       " 0.8826981351981351,\n",
       " 0.8907128982128982,\n",
       " 0.8882420357420358]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-0.2983, 0.2142, -0.9822, -0.3259])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel.bestModel.stages[0].coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.282737661939952"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel.bestModel.stages[0].intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the model using the test data. We begin by standardizing the test data using the previous standardizer object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+----------+\n",
      "|            features|label|      scaledFeatures|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+----------+\n",
      "|[2.17,0.86,12.07,...|    1|[-0.6612547258548...|[-1.2811598552068...|[0.21735285524044...|       1.0|\n",
      "|[2.17,1.08,14.83,...|    0|[-0.6612547258548...|[2.08970240664770...|[0.88989827102082...|       0.0|\n",
      "|[2.21,1.04,14.02,...|    0|[-0.5212496536054...|[0.94134911665876...|[0.71937209212416...|       0.0|\n",
      "|[2.24,0.98,13.49,...|    1|[-0.4162458494184...|[0.20425613810141...|[0.55088723704585...|       0.0|\n",
      "|[2.27,1.01,13.86,...|    0|[-0.3112420452313...|[1.09483461308741...|[0.74929101709491...|       0.0|\n",
      "|[2.3,0.72,12.82,0...|    0|[-0.2062382410443...|[-0.7155495933593...|[0.32837374459018...|       1.0|\n",
      "|[2.35,0.7,13.36,0.5]|    0|[-0.0312319007325...|[-0.0181335961903...|[0.49546672517376...|       1.0|\n",
      "|[2.41,1.15,13.75,...|    0|[0.17877570764155...|[0.84827200343774...|[0.70020453017610...|       0.0|\n",
      "|[2.42,1.05,12.0,1...|    1|[0.21377697570390...|[-1.7340782396491...|[0.15006667120506...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = scalerModel.transform(testUnSTD).cache()\n",
    "prediction = cvModel.transform(test)\n",
    "prediction.sample(False, 0.2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the probabilites for class 0 and class 1 for each record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_1</th>\n",
       "      <th>_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.091828</td>\n",
       "      <td>0.908172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.091364</td>\n",
       "      <td>0.908636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.209529</td>\n",
       "      <td>0.790471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.577755</td>\n",
       "      <td>0.422245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.408536</td>\n",
       "      <td>0.591464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         _1        _2\n",
       "0  0.091828  0.908172\n",
       "1  0.091364  0.908636\n",
       "2  0.209529  0.790471\n",
       "3  0.577755  0.422245\n",
       "4  0.408536  0.591464"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.select('probability').rdd.map(lambda row: row.probability.values.tolist()).toDF().toPandas().applymap(lambda x: round(x, 7))[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw predition is the inner product of the feature vector and the coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_1</th>\n",
       "      <th>_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.2915</td>\n",
       "      <td>2.2915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.2971</td>\n",
       "      <td>2.2971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.3278</td>\n",
       "      <td>1.3278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3136</td>\n",
       "      <td>-0.3136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.3700</td>\n",
       "      <td>0.3700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       _1      _2\n",
       "0 -2.2915  2.2915\n",
       "1 -2.2971  2.2971\n",
       "2 -1.3278  1.3278\n",
       "3  0.3136 -0.3136\n",
       "4 -0.3700  0.3700"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawPred = prediction.select('rawPrediction').rdd.map(lambda row: row.rawPrediction.values.tolist()).toDF().toPandas().applymap(lambda x: round(x, 4))[:5]\n",
    "rawPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.091829378202088724, 0.9081706217979113)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "dp = rawPred.iloc[0, 0]\n",
    "np.exp(dp) / (1 + np.exp(dp)), np.exp(-dp) / (1 + np.exp(-dp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute two quantities for evaluation purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8973913043478261"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\")\n",
    "evaluator.evaluate(prediction, {evaluator.metricName: \"areaUnderROC\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9158088615450615"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(prediction, {evaluator.metricName: \"areaUnderPR\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|label|\n",
      "+----------+-----+\n",
      "|         1|    1|\n",
      "|         1|    1|\n",
      "|         1|    1|\n",
      "|         0|    0|\n",
      "|         1|    1|\n",
      "|         1|    1|\n",
      "|         1|    1|\n",
      "|         0|    0|\n",
      "|         0|    0|\n",
      "|         1|    1|\n",
      "|         0|    1|\n",
      "|         0|    0|\n",
      "|         0|    0|\n",
      "|         1|    1|\n",
      "|         0|    0|\n",
      "|         1|    1|\n",
      "|         1|    1|\n",
      "|         1|    1|\n",
      "|         1|    0|\n",
      "|         1|    1|\n",
      "|         0|    0|\n",
      "|         1|    1|\n",
      "|         1|    0|\n",
      "|         0|    0|\n",
      "|         0|    0|\n",
      "|         1|    1|\n",
      "|         0|    0|\n",
      "|         0|    0|\n",
      "|         1|    1|\n",
      "|         0|    0|\n",
      "|         1|    1|\n",
      "|         1|    1|\n",
      "|         0|    1|\n",
      "|         0|    0|\n",
      "|         0|    1|\n",
      "|         0|    0|\n",
      "|         0|    0|\n",
      "|         0|    0|\n",
      "|         0|    0|\n",
      "|         1|    1|\n",
      "|         1|    0|\n",
      "|         0|    0|\n",
      "|         0|    0|\n",
      "|         1|    1|\n",
      "|         0|    1|\n",
      "|         0|    0|\n",
      "|         0|    0|\n",
      "|         0|    0|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_and_labels = prediction.select('prediction', 'label')\n",
    "predictions_and_labels = predictions_and_labels.withColumn('prediction', predictions_and_labels['prediction'].cast('integer'))\n",
    "predictions_and_labels.show(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp = predictions_and_labels.filter('prediction == 1 and label == 1').count()\n",
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = predictions_and_labels.filter('prediction == 1 and label == 0').count()\n",
    "fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn = predictions_and_labels.filter('prediction == 0 and label == 0').count()\n",
    "tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn = predictions_and_labels.filter('prediction == 0 and label == 1').count()\n",
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8541666666666666"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = float(tp + tn) / (tp + tn + fp + fn)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8260869565217391"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# when the answer is 1, how often were you right\n",
    "# or the proportion of positive cases that were correctly identified\n",
    "precision = float(tp) / (tp + fn)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14583333333333334"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classification error\n",
    "ce = float(fn + fp) / (tp + tn + fp + fn)\n",
    "ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8260869565217391"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sensitivity (or recall or true positive rate): when the actual value is positive, how often is the prediction correct\n",
    "# the proportion of actual positive cases which are correctly identified\n",
    "recall = float(tp) / (tp + fn)\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the proportion of actual negative cases which are correctly identified\n",
    "specificity = float(tn) / (fp + tn)\n",
    "specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (false positive rate) when the actual value is negative, how often is the prediction incorrect\n",
    "fpr = float(fp) / (tn + fp)\n",
    "fpr"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
