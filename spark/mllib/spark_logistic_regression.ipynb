{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jonathan Halverson\n",
    "# Thursday, May 12, 2016\n",
    "# Blood donations competition in Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We rework our logistic regression model from scikit-learn in Spark. We begin by loading various MLlib modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.feature import StandardScaler\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train and test data are read in, filtered and then mapped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "str_lines = sc.textFile(\"/Users/jhalverson/data_science/project_blood_donations/train_blood.csv\")\n",
    "train_rdd = str_lines.mapPartitions(lambda x: csv.reader(x)).filter(lambda x: 'Months' not in x[1]).map(lambda x: map(int, x))\n",
    "str_lines = sc.textFile(\"/Users/jhalverson/data_science/project_blood_donations/test_blood.csv\")\n",
    "test_rdd = str_lines.mapPartitions(lambda x: csv.reader(x)).filter(lambda x: 'Months' not in x[1]).map(lambda x: map(int, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.023217  ,  0.06314818,  0.06314818,  0.09836977,\n",
       "         0.04192463],\n",
       "       [-0.023217  ,  1.        , -0.15973135, -0.15973135,  0.18689945,\n",
       "        -0.26123371],\n",
       "       [ 0.06314818, -0.15973135,  1.        ,  1.        ,  0.62211596,\n",
       "         0.22061534],\n",
       "       [ 0.06314818, -0.15973135,  1.        ,  1.        ,  0.62211596,\n",
       "         0.22061534],\n",
       "       [ 0.09836977,  0.18689945,  0.62211596,  0.62211596,  1.        ,\n",
       "        -0.01981889],\n",
       "       [ 0.04192463, -0.26123371,  0.22061534,  0.22061534, -0.01981889,\n",
       "         1.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.mllib.stat import Statistics\n",
    "Statistics.corr(train_rdd, method='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove the volunteer id and blood volume column -- which is perfectly correlated with number of donations -- and add a new features which is the average number of months between donations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_features = train_rdd.map(lambda x: (x[1], x[2], x[4], float(x[4]) / x[2]))\n",
    "train_labels = train_rdd.map(lambda x: x[-1])\n",
    "test_features = test_rdd.map(lambda x: (x[1], x[2], x[4], float(x[4]) / x[2]))\n",
    "test_labels = test_rdd.map(lambda x: x[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we print out the first two records of the training set after the above transformations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 50, 98, 1.96), (0, 13, 28, 2.1538461538461537)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schema is \"Months since Last Donation\", \"Number of Donations\", \"Total Volume Donated (c.c.)\", \"Months since First Donation\", \"Made Donation in March 2007\". Because the features are of equal importance, we standardize each one such that it has mean zero and variance unity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the code fails when the scaler is fit to the training data then applied to the test data\n",
    "stdsc1 = StandardScaler(withMean=True, withStd=True).fit(train_features)\n",
    "train_features_std = stdsc1.transform(train_features)\n",
    "stdsc2 = StandardScaler(withMean=True, withStd=True).fit(test_features)\n",
    "test_features_std = stdsc2.transform(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check to see if the standardizer worked correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train means: [  2.22044605e-16   2.49800181e-16  -1.38777878e-17   2.22044605e-16]\n",
      "train variances: [ 1.  1.  1.  1.]\n",
      "test means: [  3.40005801e-16  -2.35922393e-16  -3.46944695e-16  -5.11743425e-17]\n",
      "test means: [ 1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.stat import Statistics\n",
    "train_features_std_stats = Statistics.colStats(train_features_std)\n",
    "print 'train means:', train_features_std_stats.mean()\n",
    "print 'train variances:', train_features_std_stats.variance()\n",
    "test_features_std_stats = Statistics.colStats(test_features_std)\n",
    "print 'test means:', test_features_std_stats.mean()\n",
    "print 'test means:', test_features_std_stats.variance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we create an RDD of LabeledPoints to input into the train method of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(1.0, [-0.909947819006,7.76530265869,2.63952945735,-0.911570589146]),\n",
       " LabeledPoint(1.0, [-1.15458256521,1.31932111074,-0.249728794865,-0.885241078432]),\n",
       " LabeledPoint(1.0, [-1.03226519211,1.84196826328,0.0391970303561,-0.880669982822]),\n",
       " LabeledPoint(1.0, [-0.909947819006,2.53883113333,0.451948209243,-0.872180805261]),\n",
       " LabeledPoint(0.0, [-1.03226519211,3.23569400338,1.77275198168,-0.742013415983])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "trainData = train_labels.zip(train_features_std)\n",
    "trainData = trainData.map(lambda x: LabeledPoint(x[0], np.asarray(x[1:]))).cache()\n",
    "trainData.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we instaniate a LG model and carry out the training. It appears that Spark's Python API does not support cross-validation or grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LogisticRegressionWithLBFGS.train(trainData, regParam=0.75)\n",
    "model.clearThreshold()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the weights and intercept:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0955108011026,0.0868455744526,-0.0125492435503,-0.07990835791] 0.0\n"
     ]
    }
   ],
   "source": [
    "print model.weights, model.intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we apply the model to the test data and write out the submission file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testData = test_rdd.map(lambda x: x[0]).zip(test_features_std.map(lambda x: model.predict(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('halverson_logistic_regression_may13_2016.dat', 'w')\n",
    "f.write(',Made Donation in March 2007\\n')\n",
    "for volunteer_id, prob in testData.collect():\n",
    "  f.write('%d,%.3f\\n' % (volunteer_id, prob))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
