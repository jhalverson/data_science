{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jonathan Halverson\n",
    "# Monday, December 19, 2016\n",
    "# Dating Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code uses alternating least squares to make recommendations for individuals on a dating site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import random\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 2.0.2\n"
     ]
    }
   ],
   "source": [
    "APP_NAME = \"Dating Recommender\"\n",
    "spark = SparkSession.builder.appName(APP_NAME).getOrCreate()\n",
    "print(\"Spark version: %s\" % spark.sparkContext.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_rating(line, sep=','):\n",
    "  u = line.strip().split(sep)\n",
    "  return Row(userID=int(u[0]), profileID=int(u[1]), rating=float(u[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_user(line, sep=','):\n",
    "  fields = line.strip().split(sep)\n",
    "  user_id = int(fields[0])\n",
    "  gender = fields[1]\n",
    "  return (user_id, gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the ratings data and convert to a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(profileID=8305, rating=10.0, userID=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = spark.sparkContext.textFile('ratings.dat')\n",
    "ratingsRDD = lines.map(parse_rating)\n",
    "ratingsRDD.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- profileID: long (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- userID: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings = spark.createDataFrame(ratingsRDD)\n",
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+\n",
      "|profileID|rating|userID|\n",
      "+---------+------+------+\n",
      "|     8305|  10.0|     1|\n",
      "|    15530|   6.0|     1|\n",
      "|    22319|  10.0|     1|\n",
      "|    32136|   9.0|     1|\n",
      "|    38868|   7.0|     1|\n",
      "+---------+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which users have provided the fewest ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|userID|count|\n",
      "+------+-----+\n",
      "| 10620|    1|\n",
      "| 15799|    1|\n",
      "| 10632|    1|\n",
      "|  1671|    1|\n",
      "| 11574|    1|\n",
      "+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "rating_counts = ratings.groupBy('userID').agg(F.count('*').alias('count'))\n",
    "rating_counts.sort('count', ascending=True).show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7697"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_counts.select('*').where('count >= 20').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out the users that have fewer than 20 ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2214, 2509, 7747, 10422, 16530, 17979, 18628, 19979, 22201, 25084]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_users_ids = rating_counts.rdd.map(lambda x: (x[0], x[1])).filter(lambda x: x[1] >= 20).keys()\n",
    "active_users_ids.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the ratings data into a training and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training, test = ratings.randomSplit([0.9, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 976635\n",
      "Validation: 108324\n"
     ]
    }
   ],
   "source": [
    "print('Training: %d' % training.count())\n",
    "print('Validation: %d' % test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameters for ALS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rank_ = 15\n",
    "num_iterations = 20\n",
    "lambda_ = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "als = ALS(rank=rank_, maxIter=num_iterations, regParam=lambda_, userCol=\"userID\", itemCol=\"profileID\", ratingCol=\"rating\")\n",
    "model = als.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.transform(test).dropna(how='any')\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+----------+\n",
      "|profileID|rating|userID|prediction|\n",
      "+---------+------+------+----------+\n",
      "+---------+------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "predictions.select('*').filter(predictions.prediction == float('nan')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+----------+\n",
      "|profileID|rating|userID|prediction|\n",
      "+---------+------+------+----------+\n",
      "+---------+------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select('*').filter(predictions.userID == 209).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "<type 'float'>\n"
     ]
    }
   ],
   "source": [
    "x = float('nan')\n",
    "print(x)\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(profileID=1238, rating=1.0, userID=81505, prediction=-0.8608876466751099),\n",
       " Row(profileID=1645, rating=1.0, userID=40326, prediction=2.617866277694702),\n",
       " Row(profileID=2366, rating=5.0, userID=24646, prediction=1.4188374280929565),\n",
       " Row(profileID=5518, rating=2.0, userID=104057, prediction=3.555800676345825),\n",
       " Row(profileID=5518, rating=1.0, userID=79331, prediction=1.2028555870056152),\n",
       " Row(profileID=5518, rating=3.0, userID=54180, prediction=2.5360350608825684),\n",
       " Row(profileID=6336, rating=1.0, userID=82272, prediction=0.768162727355957),\n",
       " Row(profileID=6336, rating=3.0, userID=8867, prediction=0.8140339255332947),\n",
       " Row(profileID=6336, rating=5.0, userID=92889, prediction=5.4729695320129395),\n",
       " Row(profileID=6336, rating=3.0, userID=92757, prediction=-2.0251524448394775),\n",
       " Row(profileID=6658, rating=7.0, userID=5294, prediction=3.5344796180725098),\n",
       " Row(profileID=6658, rating=6.0, userID=95776, prediction=5.444518089294434),\n",
       " Row(profileID=6658, rating=7.0, userID=86010, prediction=5.404545307159424),\n",
       " Row(profileID=6658, rating=7.0, userID=124313, prediction=7.835665702819824),\n",
       " Row(profileID=7240, rating=4.0, userID=47649, prediction=1.2641782760620117),\n",
       " Row(profileID=8592, rating=8.0, userID=103050, prediction=4.712427139282227),\n",
       " Row(profileID=9852, rating=1.0, userID=69460, prediction=8.431349754333496),\n",
       " Row(profileID=9900, rating=7.0, userID=84799, prediction=-2.924311399459839),\n",
       " Row(profileID=11858, rating=5.0, userID=90280, prediction=3.5736775398254395),\n",
       " Row(profileID=12046, rating=7.0, userID=58422, prediction=6.366790294647217)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.rdd.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|  a|  b|\n",
      "+---+---+\n",
      "|1.0|NaN|\n",
      "|NaN|2.0|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([(1.0, float('nan')), (float('nan'), 2.0)], (\"a\", \"b\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(r1=False, r2=False), Row(r1=True, r2=True)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(F.isnan(\"a\").alias(\"r1\"), F.isnan(df.a).alias(\"r2\")).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction is nan when the user has made a rating for the given profile. There are also negative values and maybe values greater than 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|            rating|        prediction|\n",
      "+-------+------------------+------------------+\n",
      "|  count|            103077|            103077|\n",
      "|   mean| 5.935727659904732|3.7773589493108948|\n",
      "| stddev|3.1045389499140006|3.9257219345143737|\n",
      "|    min|               1.0|        -27.810637|\n",
      "|    max|              10.0|         38.102245|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.describe(['rating', 'prediction']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 4.7603219941\n"
     ]
    }
   ],
   "source": [
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the top 10 female matches for userID 209 who is a male:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matchseekerID = 209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|profileID|userID|\n",
      "+---------+------+\n",
      "|        1|   209|\n",
      "|        2|   209|\n",
      "|        4|   209|\n",
      "|        5|   209|\n",
      "|        6|   209|\n",
      "|        7|   209|\n",
      "|       11|   209|\n",
      "|       19|   209|\n",
      "|       24|   209|\n",
      "|       25|   209|\n",
      "|       26|   209|\n",
      "|       27|   209|\n",
      "|       28|   209|\n",
      "|       31|   209|\n",
      "|       35|   209|\n",
      "|       36|   209|\n",
      "|       38|   209|\n",
      "|       39|   209|\n",
      "|       40|   209|\n",
      "|       42|   209|\n",
      "+---------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines = spark.sparkContext.textFile('gender.dat')\n",
    "usersRDD = lines.map(parse_user).filter(lambda x: x[1] == 'F').map(lambda x: Row(userID=matchseekerID, profileID=x[0]))\n",
    "users = spark.createDataFrame(usersRDD)\n",
    "users.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+----------+\n",
      "|profileID|userID|prediction|\n",
      "+---------+------+----------+\n",
      "|    88841|   209| 1.9209691|\n",
      "|    98161|   209| 1.5344874|\n",
      "|    55190|   209| 1.5338956|\n",
      "|    49976|   209| 1.4907684|\n",
      "|   110953|   209| 1.4170587|\n",
      "|    13250|   209|   1.36831|\n",
      "|    45285|   209| 1.3639637|\n",
      "|    63534|   209| 1.3294585|\n",
      "|   130656|   209| 1.2801224|\n",
      "|   208024|   209| 1.2697482|\n",
      "+---------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_matchseekerID = model.transform(users).dropna(how='any')\n",
    "predictions_matchseekerID.sort('prediction', ascending=False).show(n=10)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
