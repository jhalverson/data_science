{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jonathan Halverson\n",
    "# Monday, December 19, 2016\n",
    "# Dating Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code uses alternating least squares to make recommendations for individuals on a dating site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import random\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 2.0.2\n"
     ]
    }
   ],
   "source": [
    "APP_NAME = \"Dating Recommender\"\n",
    "spark = SparkSession.builder.appName(APP_NAME).getOrCreate()\n",
    "print(\"Spark version: %s\" % spark.sparkContext.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_rating(line, sep=','):\n",
    "  u = line.strip().split(sep)\n",
    "  return Row(userID=int(u[0]), profileID=int(u[1]), rating=float(u[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_user(line, sep=','):\n",
    "  fields = line.strip().split(sep)\n",
    "  user_id = int(fields[0])\n",
    "  gender = fields[1]\n",
    "  return (user_id, gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the ratings data and convert to a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(profileID=8305, rating=10.0, userID=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = spark.sparkContext.textFile('ratings.dat')\n",
    "ratingsRDD = lines.map(parse_rating)\n",
    "ratingsRDD.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- profileID: long (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- userID: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings = spark.createDataFrame(ratingsRDD)\n",
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+\n",
      "|profileID|rating|userID|\n",
      "+---------+------+------+\n",
      "|     8305|  10.0|     1|\n",
      "|    15530|   6.0|     1|\n",
      "|    22319|  10.0|     1|\n",
      "|    32136|   9.0|     1|\n",
      "|    38868|   7.0|     1|\n",
      "+---------+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which users have provided the fewest ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|userID|count|\n",
      "+------+-----+\n",
      "| 10620|    1|\n",
      "| 15799|    1|\n",
      "| 10632|    1|\n",
      "|  1671|    1|\n",
      "| 11574|    1|\n",
      "+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "rating_counts = ratings.groupBy('userID').agg(F.count('*').alias('count'))\n",
    "rating_counts.sort('count', ascending=True).show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What percentage of users have given fewer than 20 ratings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.31364002393634"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100.0 * rating_counts.select('*').where('count < 20').count() / rating_counts.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of users that have at least 20 ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2214, 2509, 7747, 10422, 16530, 17979, 18628, 19979, 22201, 25084]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_users_ids = rating_counts.rdd.map(lambda x: (x[0], x[1])).filter(lambda x: x[1] >= 20).keys()\n",
    "active_users_ids.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the ratings data into a training and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[profileID: bigint, rating: double, userID: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training, test = ratings.randomSplit([0.6, 0.4])\n",
    "training.cache()\n",
    "test.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 650812\n",
      "Validation: 434147\n"
     ]
    }
   ],
   "source": [
    "print('Training: %d' % training.count())\n",
    "print('Validation: %d' % test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameters for ALS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rank_ = 8\n",
    "num_iterations = 8\n",
    "lambda_ = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "als = ALS(rank=rank_, maxIter=num_iterations, regParam=lambda_, userCol=\"userID\", itemCol=\"profileID\", ratingCol=\"rating\")\n",
    "model = als.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the NaN elements. They arise when the predicted case in the the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+----------+\n",
      "|profileID|rating|userID|prediction|\n",
      "+---------+------+------+----------+\n",
      "|     1591|   8.0| 65105|       NaN|\n",
      "|     1591|   3.0| 95357|       NaN|\n",
      "|     2122|   8.0| 96125|       NaN|\n",
      "|     2122|   6.0| 18332|       NaN|\n",
      "|     2122|   5.0| 68011|       NaN|\n",
      "|     6466|  10.0| 40184|       NaN|\n",
      "|     8592|   8.0|103050|       NaN|\n",
      "|     8592|  10.0| 47092|       NaN|\n",
      "|    11858|   5.0| 90280|       NaN|\n",
      "|    11858|   9.0| 93019|       NaN|\n",
      "|    13832|   7.0| 33639|       NaN|\n",
      "|    14450|   2.0|135264|       NaN|\n",
      "|    14450|   2.0|112534|       NaN|\n",
      "|    15957|  10.0|108671|       NaN|\n",
      "|    18944|   7.0|  2561|       NaN|\n",
      "|    20135|   8.0| 26239|       NaN|\n",
      "|    20497|   5.0| 98815|       NaN|\n",
      "|    20497|   2.0| 77048|       NaN|\n",
      "|    20497|   4.0| 94853|       NaN|\n",
      "|    20497|   3.0|  1637|       NaN|\n",
      "+---------+------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select('*').filter(predictions.prediction == float('NaN')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop the NaN's so that we can compute the RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = predictions.dropna(how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction is NaN when the user has made a rating for the given profile. There are also negative values and maybe values greater than 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+\n",
      "|summary|           rating|        prediction|\n",
      "+-------+-----------------+------------------+\n",
      "|  count|           397403|            397403|\n",
      "|   mean|5.946074891231319|2.8578997503196395|\n",
      "| stddev|3.106971833920752|3.8439783369475093|\n",
      "|    min|              1.0|        -34.912716|\n",
      "|    max|             10.0|         32.818954|\n",
      "+-------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.describe(['rating', 'prediction']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 5.39798749093\n"
     ]
    }
   ],
   "source": [
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the top 10 female matches for userID 209 who is a male:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matchseekerID = 209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|profileID|userID|\n",
      "+---------+------+\n",
      "|        1|   209|\n",
      "|        2|   209|\n",
      "|        4|   209|\n",
      "|        5|   209|\n",
      "|        6|   209|\n",
      "|        7|   209|\n",
      "|       11|   209|\n",
      "|       19|   209|\n",
      "|       24|   209|\n",
      "|       25|   209|\n",
      "|       26|   209|\n",
      "|       27|   209|\n",
      "|       28|   209|\n",
      "|       31|   209|\n",
      "|       35|   209|\n",
      "|       36|   209|\n",
      "|       38|   209|\n",
      "|       39|   209|\n",
      "|       40|   209|\n",
      "|       42|   209|\n",
      "+---------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines = spark.sparkContext.textFile('gender.dat')\n",
    "usersRDD = lines.map(parse_user).filter(lambda x: x[1] == 'F').map(lambda x: Row(userID=matchseekerID, profileID=x[0]))\n",
    "users = spark.createDataFrame(usersRDD)\n",
    "users.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+----------+\n",
      "|profileID|userID|prediction|\n",
      "+---------+------+----------+\n",
      "|    24443|   209| 1.8492653|\n",
      "|    91260|   209| 1.8375853|\n",
      "|    94648|   209| 1.7534904|\n",
      "|    54181|   209| 1.7020448|\n",
      "|     8246|   209| 1.6635846|\n",
      "|    22958|   209| 1.6568315|\n",
      "|    24697|   209| 1.6375257|\n",
      "|    54808|   209| 1.6334382|\n",
      "|   124865|   209| 1.6285427|\n",
      "|    91757|   209| 1.6153195|\n",
      "+---------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_matchseekerID = model.transform(users).dropna(how='any')\n",
    "predictions_matchseekerID.sort('prediction', ascending=False).show(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mnay of the results in the notebook deserve more attention. This is thought to be because so many users only have a few ratings."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
