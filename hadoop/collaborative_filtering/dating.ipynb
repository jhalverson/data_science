{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jonathan Halverson\n",
    "# Monday, December 19, 2016\n",
    "# Dating Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code uses alternating least squares to make recommendations for individuals on a dating site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import random\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 2.0.2\n"
     ]
    }
   ],
   "source": [
    "APP_NAME = \"Dating Recommender\"\n",
    "spark = SparkSession.builder.appName(APP_NAME).getOrCreate()\n",
    "print(\"Spark version: %s\" % spark.sparkContext.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_rating(line, sep=','):\n",
    "  u = line.strip().split(sep)\n",
    "  return Row(userID=int(u[0]), profileID=int(u[1]), rating=float(u[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_user(line, sep=','):\n",
    "  fields = line.strip().split(sep)\n",
    "  user_id = int(fields[0])\n",
    "  gender = fields[1]\n",
    "  return (user_id, gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the ratings data and convert to a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(profileID=8305, rating=10.0, userID=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = spark.sparkContext.textFile('ratings.dat')\n",
    "ratingsRDD = lines.map(parse_rating)\n",
    "ratingsRDD.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- profileID: long (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- userID: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings = spark.createDataFrame(ratingsRDD)\n",
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+\n",
      "|profileID|rating|userID|\n",
      "+---------+------+------+\n",
      "|     8305|  10.0|     1|\n",
      "|    15530|   6.0|     1|\n",
      "|    22319|  10.0|     1|\n",
      "|    32136|   9.0|     1|\n",
      "|    38868|   7.0|     1|\n",
      "+---------+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which users have provided the fewest ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|userID|count|\n",
      "+------+-----+\n",
      "|  4872|    1|\n",
      "|  9954|    1|\n",
      "|  5107|    1|\n",
      "|  1921|    1|\n",
      "|  6225|    1|\n",
      "+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "rating_counts = ratings.groupBy('userID').agg(F.count('*').alias('count'))\n",
    "rating_counts.sort('count', ascending=True).show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What percentage of users have given fewer than 20 ratings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.31364002393634"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100.0 * rating_counts.select('*').where('count < 20').count() / rating_counts.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of users that have at least 20 ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2214, 2509, 7747, 10422, 16530, 17979, 18628, 19979, 22201, 25084]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_users_ids = rating_counts.rdd.map(lambda x: (x[0], x[1])).filter(lambda x: x[1] >= 20).keys()\n",
    "active_users_ids.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the ratings data into a training and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training, test = ratings.randomSplit([0.6, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 651287\n",
      "Validation: 433672\n"
     ]
    }
   ],
   "source": [
    "print('Training: %d' % training.count())\n",
    "print('Validation: %d' % test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameters for ALS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rank_ = 8\n",
    "num_iterations = 8\n",
    "lambda_ = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "als = ALS(rank=rank_, maxIter=num_iterations, regParam=lambda_, userCol=\"userID\", itemCol=\"profileID\", ratingCol=\"rating\")\n",
    "model = als.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the NaN elements. They arise when the predicted case in the the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+----------+\n",
      "|profileID|rating|userID|prediction|\n",
      "+---------+------+------+----------+\n",
      "|     7240|   3.0| 85290|       NaN|\n",
      "|     7993|  10.0| 95479|       NaN|\n",
      "|    13832|   7.0| 33639|       NaN|\n",
      "|    13840|   4.0| 86208|       NaN|\n",
      "|    14450|   2.0|135264|       NaN|\n",
      "|    15447|  10.0| 47694|       NaN|\n",
      "|    15846|   7.0| 33827|       NaN|\n",
      "|    16861|   3.0| 53467|       NaN|\n",
      "|    16861|   5.0|108503|       NaN|\n",
      "|    17420|  10.0|  4627|       NaN|\n",
      "|    20497|   5.0| 45123|       NaN|\n",
      "|    20497|   6.0| 84942|       NaN|\n",
      "|    24171|   1.0| 15196|       NaN|\n",
      "|    25462|   1.0|108348|       NaN|\n",
      "|    26087|   2.0| 44957|       NaN|\n",
      "|    26087|   6.0| 54594|       NaN|\n",
      "|    26708|  10.0| 13816|       NaN|\n",
      "|    27484|   1.0| 69509|       NaN|\n",
      "|    27484|   1.0| 72563|       NaN|\n",
      "|    29719|   2.0|132207|       NaN|\n",
      "+---------+------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select('*').filter(predictions.prediction == float('NaN')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop the NaN's so that we can compute the RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = predictions.dropna(how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction is NaN when the user has made a rating for the given profile. There are also negative values and maybe values greater than 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+\n",
      "|summary|           rating|        prediction|\n",
      "+-------+-----------------+------------------+\n",
      "|  count|           396812|            396812|\n",
      "|   mean|5.947468826547584|3.5264682021156197|\n",
      "| stddev|3.103842902712731| 3.532751096253791|\n",
      "|    min|              1.0|        -27.878664|\n",
      "|    max|             10.0|         28.086868|\n",
      "+-------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.describe(['rating', 'prediction']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 4.65859018648\n"
     ]
    }
   ],
   "source": [
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the top 10 female matches for userID 209 who is a male:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matchseekerID = 209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|profileID|userID|\n",
      "+---------+------+\n",
      "|        1|   209|\n",
      "|        2|   209|\n",
      "|        4|   209|\n",
      "|        5|   209|\n",
      "|        6|   209|\n",
      "|        7|   209|\n",
      "|       11|   209|\n",
      "|       19|   209|\n",
      "|       24|   209|\n",
      "|       25|   209|\n",
      "|       26|   209|\n",
      "|       27|   209|\n",
      "|       28|   209|\n",
      "|       31|   209|\n",
      "|       35|   209|\n",
      "|       36|   209|\n",
      "|       38|   209|\n",
      "|       39|   209|\n",
      "|       40|   209|\n",
      "|       42|   209|\n",
      "+---------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines = spark.sparkContext.textFile('gender.dat')\n",
    "usersRDD = lines.map(parse_user).filter(lambda x: x[1] == 'F').map(lambda x: Row(userID=matchseekerID, profileID=x[0]))\n",
    "users = spark.createDataFrame(usersRDD)\n",
    "users.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+----------+\n",
      "|profileID|userID|prediction|\n",
      "+---------+------+----------+\n",
      "|   128085|   209| 1.8326111|\n",
      "|    94750|   209| 1.7952724|\n",
      "|    51525|   209| 1.7804391|\n",
      "|    83952|   209| 1.7723638|\n",
      "|    29160|   209| 1.7341098|\n",
      "|    52622|   209| 1.6950321|\n",
      "|   117877|   209| 1.6577109|\n",
      "|    79726|   209| 1.6481326|\n",
      "|     8451|   209| 1.6433898|\n",
      "|   107691|   209| 1.6325084|\n",
      "+---------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_matchseekerID = model.transform(users).dropna(how='any')\n",
    "predictions_matchseekerID.sort('prediction', ascending=False).show(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mnay of the results in the notebook deserve more attention. This is thought to be because so many users only have a few ratings."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
