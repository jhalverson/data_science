First I needed to get files from my laptop to HDFS. This
is done by first uploading the files to S3.

To connect to the EMR cluster do:

ssh -i boston_data_fest2015.pem hadoop@ec2-174-129-121-227.compute-1.amazonaws.com

Note that -i specifies the RSA key. This command was run
from the directory containing the pem file but one could
specify the path instead.

Then from the command line do:

hadoop fs -get s3://fridaybucket/WordCount.java WordCount.java

Note that when you ssh to the cluster you are on a Linux
machine:

[hadoop@ip-172-31-14-252 ~]$ uname -a
Linux ip-172-31-14-252 4.4.19-29.55.amzn1.x86_64 #1 SMP Mon Aug 29 23:29:40 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux

Run 'cat /proc/cpuinfo' to see that you are on a quad-
processor (core) Intel Xeon machine.

### files in the home directory of my Linux box (local)
[hadoop@ip-172-31-14-252 ~]$ ls -l
total 12
-rw-r--r-- 1 hadoop hadoop  561 Nov 16 22:48 SumReducer.java
-rw-r--r-- 1 hadoop hadoop 1629 Nov 16 21:27 WordCount.java
-rw-r--r-- 1 hadoop hadoop  747 Nov 16 22:48 WordMapper.java

### there is nothing on hdfs (remote) yet
[hadoop@ip-172-31-14-252 ~]$ hadoop fs -ls .

### copy files to hdfs
[hadoop@ip-172-31-14-252 ~]$ hadoop fs -put WordMapper.java WordMapper.java 
[hadoop@ip-172-31-14-252 ~]$ 
[hadoop@ip-172-31-14-252 ~]$ hadoop fs -ls .
Found 3 items
-rw-r--r--   1 hadoop hadoop        561 2016-11-16 23:11 SumReducer.java
-rw-r--r--   1 hadoop hadoop       1629 2016-11-16 23:12 WordCount.java
-rw-r--r--   1 hadoop hadoop        747 2016-11-16 23:12 WordMapper.java

To get from hdfs to s3:

hadoop fs -put BinaryFiles s3://mybucket/BinaryDestination


One can explore the hdfs root directories:

[hadoop@ip-172-31-3-215 ~]$ hadoop fs -ls /
drwxr-xr-x   - hdfs hadoop          0 2016-11-17 18:58 /apps
drwxrwxrwt   - hdfs hadoop          0 2016-11-17 19:05 /tmp
drwxr-xr-x   - hdfs hadoop          0 2016-11-17 18:58 /user
drwxr-xr-x   - hdfs hadoop          0 2016-11-17 18:58 /var

[hadoop@ip-172-31-3-215 ~]$ hadoop fs -ls /user
drwxrwxrwx   - hadoop hadoop          0 2016-11-17 19:06 /user/hadoop
drwxr-xr-x   - mapred mapred          0 2016-11-17 18:58 /user/history
drwxrwxrwx   - hdfs   hadoop          0 2016-11-17 18:58 /user/hive
drwxrwxrwx   - hue    hue             0 2016-11-17 18:58 /user/hue
drwxrwxrwx   - oozie  oozie           0 2016-11-17 19:04 /user/oozie
drwxrwxrwx   - root   hadoop          0 2016-11-17 18:58 /user/root


## Let's set some environment variables
export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.111-1.b15.25.amzn1.x86_64
export HADOOP_CLASSPATH=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.111-1.b15.25.amzn1.x86_64/lib
export HADOOP_HOME=/usr/lib/hadoop # not sure if this is right
export PATH=$PATH:$HADOOP_HOME/bin
export HADOOP_STREAMING=/usr/lib/hadoop/hadoop-streaming-2.7.3-amzn-0.jar
