Weapons of Math Destruction
Cathy O'Neil

== Introduction ==

Author worked for a period on trying to forecast the global financial markets.
It should be possible to scrape FaceBook. Do they allow private companies to
do this?

Machine learning models based on big data tend to be opaque and give results
which are impossible to interpret cleanly. That is, they have essentially
no explainability. In 2007 the schools in Washington DC were failing. A plan
was enacted to test the teachers and fired the lower performers. This would be
decided based on a ML model based on big data by the firm Mathematica. A fifth
grade teacher named Sarah Wysocki was fired despite having an excellent reptu-
tation. The author points out that it is very difficult to decide who is
a bad teacher since so much depends on the students. A class size of only 20-30
students leads to bad statistics. The fired teacher complained that beside the
model is such a mystery (black box), it is not clear why she was fired. Furth-
ermore, it was found that there were excessive erasure marks on the 4th grade
test sheets suggesting that the teachers were  changing the grades since the
new program granted $8000 to the top performing teachers. The teacher and 205
others remained fired.


== Bomb Parts ==

Baseball models work well because the modelers have a vast amount and variety
of data. While the model may be complex, they are not trying makeing their
predictions based on inane factors like how much the catcher celebrated when
the player got struck out. This is in contrast to how the DC teachers were
being judged where much of their score was based on annual improvement with-
out regard to the personal issues in the students lives.

The LSI-R is a model used to inform judges about how long of a sentence they
should assign to a convicted criminal. The input data is based on the answers
on a questionnaire by the criminal. It includes whether or not the person
has had family members jailed, which is strange because that is largely out
of the persons control. Note: One can try to use a persons zip code or
language patterns to learn about their socioeconomic class. Also, models
contain the ideology and goals of the modeler. Models must be updated over
time -- the Google model for flu outbreak was not and this was in part why it
later failed.

Recidivism is the tendency of a convicted criminal to reoffend. Statistical
studies have shown that judges across the US tend to sentence blacks to longer
sentences than other racial groups for the same crimes. Blacks constitute 13%
of the population but between 40-50% of the jail population. To remove this
bias it would seem wise to use a computer model which does not take into acc-
out the person's race. However, as described above this can lead to new prob-
lems. The author argues that the LSI-R is biased and sets up a positive feed-
back loop of destruction. The model is used in 24 states since 1995.

Models tend to be black boxes due to their complexity and because they are
intellectual property. A WMD is opaque, scales and does damage to people. Such
models can leap from one field to another which causes more damaged and fast.
The author points out the negative effects of uses such models and identifies
specific groups that are the most hurt. She also admits that much good comes
from the models. The reader is left wondering why doesn't she simply argue to
keep the model but specifically make sure the at-risk groups are not harmed.
This would seem to solve all the problems.


== Shell Shocked ==

The author went to work at a hedge fund (D. E. Shaw in NYC) where she worked
as a quantative analyst. This was during the 2008 housing collapse, which is
explained in detail. The use of models was partly to blame for the collapse
so the author puts out that they witnessed the tangible faces of the people
who were affected -- this is often not the case.

She then left the hedge fund to work at RiskMetrics Group which was a company
that helped banks estimate risk. But banks had their own teams so they were
merely brought in for cosmetics. They used Monte Carlo methods. "There was
plenty to complain about with this method, but it was a simple way to get
some handle on your risk." However, traders like to under report risk because
it gives them a better Sharpe ratio which leads to a bigger bonus. So the
author's work was largely ignored and she left to become a data scientist
in 2011 as Intent Media.

Her first job was to create a model that distinguished people browsing a
travel website versus those looking to buy. Visitors who were logged in or
had bought before were immediately considered to be buying. Time of day and
year proved to be important. Everyone books summer vaction the last week
of May. The author was trying to predict people's clicks instead of the
movement of markets. Will the big data world lead to a collapse analogous
to that of the housing market? The author didn't want to be a part of the
problem so she quit her job. She views these models as keeping the poor in
their place while the rich prosper.


== Arms Race ==

Flutie effect is when an elevated number of students apply to a college after
one of its sports team have done well.

US News & World report came out with their college rankings in 1983. A few
years later the rankings were based on data like acceptance rate, SAT, grad-
uation rates, donations from alum, etc. The public believed the rankings and
this caused university presidents to get their school the best ranking. 25% of
the score is not measured but by opinion. Several schools in recent years have
resorted to cheating by lying on the numbers.

Schools use models to determine who to accept. Because they aim to keep their
acceptance rates low, some will reject students who they think are applying to
the school as a safety. The universities are gaming the model. A math dept in
Saudi Arabia paid adjunct faculty to switch their affilitions on their publications.

From 1985-2013 there was a 500% increase in tuition which was 4 times greater
than inflation. Tuition was raised to have more resources to improve the 15 variables
used by US News.

TCU spent nearly 500 million from 2008 to 2015 to move ranking from 97 to 76.

There is an entire industry around getting kids to college. 4-day essay writing
boot camps can cost 16k. One company estimates the probability of a student getting
accepted at a certain college then charges 25k to help the student get accepted
(if the student gets accepted; see ThinkTank Learning).

The rankings do not count tuition and fees.

Obama tried to introduce new rankings that included cost and population of minor-
ities and the poor but failed. Instead the project resulted in a web site with lots
of data on each school so students can decide. University presidents resisted the new
rankings because they had worked so long to optimize for US News.


== Propaganda Machine ==

Many think targeted advertising will be want people want. US News made life
miserable for rich and middle-class. Low class was targeted by for-profit colleges
which are those run by a business behind it like Trump University, ITT Tech and
University of Pheonix, DeVry.

Here the main point is predatory ads and lead generation and pursuing people who
are weak. Recuiters are told to find the pain point. They seek people in the poor-
est zip codes. They pursue veterans because it is easy to get funding for them. A
feedback loop makes the poor even poorer.


== Civilian Casualties ==

PredPol or predictive policing is software that reads in historical crime data and
instructs patrolling officiers where to patrol and when to prevent crime. The blocks
are the size of two football fields. NYC officers are under pressure to diminish
crime so they at times don't report a crime -- similar to the case of Robert S.
McNamara during Vietnam war. HunchLab is being used in Philedelphia. One parameter
is whether the baseball go is home or away. These are hot-spot predictors and they
are similar to how baseball fielders move to certain areas for a given batter. The
model is explicitly blind to race and ethnicity. When nuisance crimes are added to
the model (things like public drinking) then the model will focus on these crimes
because there are so many more of them and it will effectively draw the police into
the poorest neighborhoods. If nuisance data is ignored then these neighborhoods will
tend to bread more serious crimes. This is why zero-tolerance campaigns have been
introduced in places like NYC. This is broken-window policing where the windows must
be fixed otherwise people will assume the neighborhood is junk and commit more serious
crimes. The net result is that poverty is criminalized.

Stop and frisk targeted minorities. 1 in 1000 had a gun. It is still in practice.
